{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNidD4T4gtdxIlTLimmunK+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jiadia22/2024-deep-learning-training/blob/main/DL_training_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "경사 하강법을 이용한 얕은 신경망 학습"
      ],
      "metadata": {
        "id": "pEiHgor8Ov4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1cZVgLmTO4SN"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#하이퍼 파라미터 설정\n",
        "EPOCHS = 1000"
      ],
      "metadata": {
        "id": "Uyzq8F05b5hp"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#네트워크 구조 정의\n",
        "#얕은 신경망. 입력계층:2, 은닉계층:128(sigmoid activation),출력계층:10(softmax activation)"
      ],
      "metadata": {
        "id": "OnOsPERyb5pK"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model): #초기화 메서드\n",
        "  def __init__(self):\n",
        "    super(MyModel,self).__init__() #tf.keras.Model클래스의 초기화 메서드 호출.\n",
        "\n",
        "\n",
        "    self.d1 = tf.keras.layers.Dense(128,input_dim=2,activation='sigmoid')\n",
        "    self.d2 = tf.keras.layers.Dense(10,activation='softmax') #input_dim=128\n",
        "\n",
        "  def call(self,x,training=None,mask=None): #호출 메서드\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "#입력 데이터에 대해 순전파를 수행하여 클래스의 확률 분포를 출력하는 간단한 신경망 모델."
      ],
      "metadata": {
        "id": "ZaJe4jTGb5r4"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 루프 정의\n",
        "@tf.function #파이썬 코드를 tensorflow 그래프로 변환하여 성능을 향상시키는 역할\n",
        "def train_step(model,inputs,labels,loss_object,optimizer,train_loss,train_metric):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(inputs)\n",
        "    loss = loss_object(labels,predictions)\n",
        "  gradients = tape.gradient(loss,model.trainable_variables) #df(x)/dx, 손실에 대한 모델의 각 변수에 대한 경사를 계산\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
        "  #옵티마이저를 사용하여 모델의 변수들을 업데이트합니다.\n",
        "  train_loss(loss) #현재의 손실을 train_loss에 기록\n",
        "  train_metric(labels,predictions) #정확도 등을 계산하고 기록합니다"
      ],
      "metadata": {
        "id": "HytqqQ6RFVGF"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋 생성,전처리\n",
        "np.random.seed(0)\n",
        "\n",
        "pts = list() #2개\n",
        "labels = list() #10개\n",
        "center_pts_list = np.random.uniform(-8.0,8.0,(10,2)) #10개의 중심점 생성\n",
        "for label,center_pts in enumerate(center_pts_list): #각 중심점 주변에 표준 정규 분포를 따르는 100개의 데이터 포인트 생성\n",
        "  for _ in range(100):\n",
        "    pts.append(center_pts + np.random.randn(*center_pts.shape))\n",
        "    labels.append(label)\n",
        "\n",
        "pts = np.stack(pts,axis=0).astype(np.float32) #리스트를 넘파이\n",
        "labels = np.stack(labels,axis=0)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((pts,labels)).shuffle(1000).batch(32)\n",
        "#튜플형태로 데이터셋 생성, 1000개의 데이터를 섞기, 한 번에 처리할 수 있는 배치크기는 32."
      ],
      "metadata": {
        "id": "pKNkfIOmFVHI"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델생성\n",
        "model = MyModel()"
      ],
      "metadata": {
        "id": "GfAmCXp-FVIU"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#손실 함수 및 최적화 알고리즘 설정\n",
        "#(crossentropy, adam optimizer)\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy() #크로스엔트로피를 최소화 해야함\n",
        "optimizer = tf.keras.optimizers.Adam() #모델의 가중치 업데이트"
      ],
      "metadata": {
        "id": "wIDx8H45FVJ2"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#평가 지표 설정 (accuracy)\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss') #손실 값을 평균화 하여 기록\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalCrossentropy(name='train_accuracy') #정확도 평"
      ],
      "metadata": {
        "id": "nBP-ee3CFVK0"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습루프\n",
        "for epoch in range(EPOCHS):\n",
        "  for x,label in train_ds: #32\n",
        "    train_step(model,x,label,loss_object,optimizer,train_loss,train_accuracy)\n",
        "\n",
        "  template = 'Epoch {}, Loss: {}, Accuracy: {}'\n",
        "  print(template.format(epoch+1,\n",
        "                        train_loss.result(), #현재까지의 평균 손실\n",
        "                        train_accuracy.result()*100)) #현재까지의 평균 정확도"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVqBBO2tFVL7",
        "outputId": "77471708-ecc4-440a-fe53-4719de1ab0cb"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.1445233821868896, Accuracy: 214.4814453125\n",
            "Epoch 2, Loss: 1.9786162376403809, Accuracy: 198.13705444335938\n",
            "Epoch 3, Loss: 1.8487874269485474, Accuracy: 185.23910522460938\n",
            "Epoch 4, Loss: 1.7427117824554443, Accuracy: 174.69007873535156\n",
            "Epoch 5, Loss: 1.6539747714996338, Accuracy: 165.75160217285156\n",
            "Epoch 6, Loss: 1.5775152444839478, Accuracy: 158.1053009033203\n",
            "Epoch 7, Loss: 1.5111072063446045, Accuracy: 151.37513732910156\n",
            "Epoch 8, Loss: 1.4514983892440796, Accuracy: 145.46238708496094\n",
            "Epoch 9, Loss: 1.3985669612884521, Accuracy: 140.1352081298828\n",
            "Epoch 10, Loss: 1.350815773010254, Accuracy: 135.39553833007812\n",
            "Epoch 11, Loss: 1.3073813915252686, Accuracy: 131.02806091308594\n",
            "Epoch 12, Loss: 1.2674156427383423, Accuracy: 127.05763244628906\n",
            "Epoch 13, Loss: 1.230790376663208, Accuracy: 123.38341522216797\n",
            "Epoch 14, Loss: 1.1970512866973877, Accuracy: 119.99575805664062\n",
            "Epoch 15, Loss: 1.1659789085388184, Accuracy: 116.86202239990234\n",
            "Epoch 16, Loss: 1.136704683303833, Accuracy: 113.92054748535156\n",
            "Epoch 17, Loss: 1.1095616817474365, Accuracy: 111.17288208007812\n",
            "Epoch 18, Loss: 1.0838621854782104, Accuracy: 108.60409545898438\n",
            "Epoch 19, Loss: 1.0598688125610352, Accuracy: 106.19428253173828\n",
            "Epoch 20, Loss: 1.037182092666626, Accuracy: 103.93241882324219\n",
            "Epoch 21, Loss: 1.0156996250152588, Accuracy: 101.79656982421875\n",
            "Epoch 22, Loss: 0.995635449886322, Accuracy: 99.77350616455078\n",
            "Epoch 23, Loss: 0.9764232635498047, Accuracy: 97.85795593261719\n",
            "Epoch 24, Loss: 0.958552360534668, Accuracy: 96.05207824707031\n",
            "Epoch 25, Loss: 0.9414962530136108, Accuracy: 94.33063507080078\n",
            "Epoch 26, Loss: 0.9251139760017395, Accuracy: 92.69060516357422\n",
            "Epoch 27, Loss: 0.9095026850700378, Accuracy: 91.12077331542969\n",
            "Epoch 28, Loss: 0.8946290612220764, Accuracy: 89.63090515136719\n",
            "Epoch 29, Loss: 0.8806440234184265, Accuracy: 88.2086181640625\n",
            "Epoch 30, Loss: 0.8670235276222229, Accuracy: 86.85440826416016\n",
            "Epoch 31, Loss: 0.8538903594017029, Accuracy: 85.55570983886719\n",
            "Epoch 32, Loss: 0.8414633274078369, Accuracy: 84.30506134033203\n",
            "Epoch 33, Loss: 0.8294822573661804, Accuracy: 83.1064453125\n",
            "Epoch 34, Loss: 0.8178660869598389, Accuracy: 81.95367431640625\n",
            "Epoch 35, Loss: 0.8070986866950989, Accuracy: 80.85099792480469\n",
            "Epoch 36, Loss: 0.7967357039451599, Accuracy: 79.79151916503906\n",
            "Epoch 37, Loss: 0.786871612071991, Accuracy: 78.77081298828125\n",
            "Epoch 38, Loss: 0.7773140668869019, Accuracy: 77.79804229736328\n",
            "Epoch 39, Loss: 0.7678905725479126, Accuracy: 76.8521957397461\n",
            "Epoch 40, Loss: 0.7587830424308777, Accuracy: 75.94292449951172\n",
            "Epoch 41, Loss: 0.750176191329956, Accuracy: 75.0674819946289\n",
            "Epoch 42, Loss: 0.7417863607406616, Accuracy: 74.21681213378906\n",
            "Epoch 43, Loss: 0.7335477471351624, Accuracy: 73.3981704711914\n",
            "Epoch 44, Loss: 0.7256834506988525, Accuracy: 72.6051025390625\n",
            "Epoch 45, Loss: 0.7180263996124268, Accuracy: 71.84021759033203\n",
            "Epoch 46, Loss: 0.7105430960655212, Accuracy: 71.10208892822266\n",
            "Epoch 47, Loss: 0.7033416032791138, Accuracy: 70.38861846923828\n",
            "Epoch 48, Loss: 0.696730375289917, Accuracy: 69.69501495361328\n",
            "Epoch 49, Loss: 0.6899909377098083, Accuracy: 69.02633666992188\n",
            "Epoch 50, Loss: 0.6834347248077393, Accuracy: 68.37316131591797\n",
            "Epoch 51, Loss: 0.6771596074104309, Accuracy: 67.74403381347656\n",
            "Epoch 52, Loss: 0.6709747314453125, Accuracy: 67.12986755371094\n",
            "Epoch 53, Loss: 0.664957582950592, Accuracy: 66.53179931640625\n",
            "Epoch 54, Loss: 0.6591178774833679, Accuracy: 65.9537124633789\n",
            "Epoch 55, Loss: 0.6535078287124634, Accuracy: 65.39257049560547\n",
            "Epoch 56, Loss: 0.6481220126152039, Accuracy: 64.84701538085938\n",
            "Epoch 57, Loss: 0.6427704691886902, Accuracy: 64.31478881835938\n",
            "Epoch 58, Loss: 0.6376090049743652, Accuracy: 63.794281005859375\n",
            "Epoch 59, Loss: 0.6326349377632141, Accuracy: 63.29212188720703\n",
            "Epoch 60, Loss: 0.6278011202812195, Accuracy: 62.80290603637695\n",
            "Epoch 61, Loss: 0.6230508685112, Accuracy: 62.32424545288086\n",
            "Epoch 62, Loss: 0.6183297634124756, Accuracy: 61.85646057128906\n",
            "Epoch 63, Loss: 0.6138399839401245, Accuracy: 61.400367736816406\n",
            "Epoch 64, Loss: 0.6094938516616821, Accuracy: 60.9598503112793\n",
            "Epoch 65, Loss: 0.6050918102264404, Accuracy: 60.52743911743164\n",
            "Epoch 66, Loss: 0.6008005142211914, Accuracy: 60.105289459228516\n",
            "Epoch 67, Loss: 0.5966562032699585, Accuracy: 59.69163131713867\n",
            "Epoch 68, Loss: 0.5926385521888733, Accuracy: 59.287811279296875\n",
            "Epoch 69, Loss: 0.5888243913650513, Accuracy: 58.894805908203125\n",
            "Epoch 70, Loss: 0.5850843191146851, Accuracy: 58.516056060791016\n",
            "Epoch 71, Loss: 0.5813472270965576, Accuracy: 58.143585205078125\n",
            "Epoch 72, Loss: 0.5778284072875977, Accuracy: 57.77745819091797\n",
            "Epoch 73, Loss: 0.5742137432098389, Accuracy: 57.42055130004883\n",
            "Epoch 74, Loss: 0.570631206035614, Accuracy: 57.06930160522461\n",
            "Epoch 75, Loss: 0.5671988129615784, Accuracy: 56.728233337402344\n",
            "Epoch 76, Loss: 0.5638134479522705, Accuracy: 56.3983039855957\n",
            "Epoch 77, Loss: 0.5604903697967529, Accuracy: 56.06951904296875\n",
            "Epoch 78, Loss: 0.5572891235351562, Accuracy: 55.7475700378418\n",
            "Epoch 79, Loss: 0.5541126132011414, Accuracy: 55.43381118774414\n",
            "Epoch 80, Loss: 0.5510659217834473, Accuracy: 55.12399673461914\n",
            "Epoch 81, Loss: 0.5480362772941589, Accuracy: 54.8209114074707\n",
            "Epoch 82, Loss: 0.5450499057769775, Accuracy: 54.525543212890625\n",
            "Epoch 83, Loss: 0.542198121547699, Accuracy: 54.23952865600586\n",
            "Epoch 84, Loss: 0.5392724275588989, Accuracy: 53.954349517822266\n",
            "Epoch 85, Loss: 0.536453366279602, Accuracy: 53.67435836791992\n",
            "Epoch 86, Loss: 0.53372722864151, Accuracy: 53.40325927734375\n",
            "Epoch 87, Loss: 0.531059205532074, Accuracy: 53.13569259643555\n",
            "Epoch 88, Loss: 0.5283803939819336, Accuracy: 52.87295150756836\n",
            "Epoch 89, Loss: 0.5258259177207947, Accuracy: 52.61417770385742\n",
            "Epoch 90, Loss: 0.5232677459716797, Accuracy: 52.36185836791992\n",
            "Epoch 91, Loss: 0.5207489132881165, Accuracy: 52.11448669433594\n",
            "Epoch 92, Loss: 0.5182778835296631, Accuracy: 51.871185302734375\n",
            "Epoch 93, Loss: 0.5158444046974182, Accuracy: 51.631290435791016\n",
            "Epoch 94, Loss: 0.5134878754615784, Accuracy: 51.396358489990234\n",
            "Epoch 95, Loss: 0.5112506151199341, Accuracy: 51.16642761230469\n",
            "Epoch 96, Loss: 0.508984386920929, Accuracy: 50.941532135009766\n",
            "Epoch 97, Loss: 0.5067728757858276, Accuracy: 50.72195053100586\n",
            "Epoch 98, Loss: 0.5045710802078247, Accuracy: 50.5037956237793\n",
            "Epoch 99, Loss: 0.5023903250694275, Accuracy: 50.2885627746582\n",
            "Epoch 100, Loss: 0.5002609491348267, Accuracy: 50.07717514038086\n",
            "Epoch 101, Loss: 0.49817320704460144, Accuracy: 49.8685417175293\n",
            "Epoch 102, Loss: 0.49624356627464294, Accuracy: 49.667510986328125\n",
            "Epoch 103, Loss: 0.4942653179168701, Accuracy: 49.4693603515625\n",
            "Epoch 104, Loss: 0.4922754466533661, Accuracy: 49.27244186401367\n",
            "Epoch 105, Loss: 0.4903205931186676, Accuracy: 49.07874298095703\n",
            "Epoch 106, Loss: 0.4883915185928345, Accuracy: 48.88896179199219\n",
            "Epoch 107, Loss: 0.4865214228630066, Accuracy: 48.70037078857422\n",
            "Epoch 108, Loss: 0.48464569449424744, Accuracy: 48.51642608642578\n",
            "Epoch 109, Loss: 0.48278847336769104, Accuracy: 48.33373260498047\n",
            "Epoch 110, Loss: 0.4810272455215454, Accuracy: 48.15484619140625\n",
            "Epoch 111, Loss: 0.4793093502521515, Accuracy: 47.97943115234375\n",
            "Epoch 112, Loss: 0.4775769114494324, Accuracy: 47.807151794433594\n",
            "Epoch 113, Loss: 0.47590532898902893, Accuracy: 47.63501739501953\n",
            "Epoch 114, Loss: 0.4743087887763977, Accuracy: 47.466243743896484\n",
            "Epoch 115, Loss: 0.47260427474975586, Accuracy: 47.299957275390625\n",
            "Epoch 116, Loss: 0.470984548330307, Accuracy: 47.138404846191406\n",
            "Epoch 117, Loss: 0.469363808631897, Accuracy: 46.97760772705078\n",
            "Epoch 118, Loss: 0.4677738547325134, Accuracy: 46.82011413574219\n",
            "Epoch 119, Loss: 0.4662230908870697, Accuracy: 46.663047790527344\n",
            "Epoch 120, Loss: 0.4646930694580078, Accuracy: 46.510833740234375\n",
            "Epoch 121, Loss: 0.4631662666797638, Accuracy: 46.35901641845703\n",
            "Epoch 122, Loss: 0.46163684129714966, Accuracy: 46.21034240722656\n",
            "Epoch 123, Loss: 0.46012333035469055, Accuracy: 46.06295394897461\n",
            "Epoch 124, Loss: 0.4587022066116333, Accuracy: 45.917972564697266\n",
            "Epoch 125, Loss: 0.4573269188404083, Accuracy: 45.77627182006836\n",
            "Epoch 126, Loss: 0.4559136629104614, Accuracy: 45.63797378540039\n",
            "Epoch 127, Loss: 0.4545332193374634, Accuracy: 45.497928619384766\n",
            "Epoch 128, Loss: 0.4531967043876648, Accuracy: 45.36235809326172\n",
            "Epoch 129, Loss: 0.4518846869468689, Accuracy: 45.22720718383789\n",
            "Epoch 130, Loss: 0.4505258798599243, Accuracy: 45.09447479248047\n",
            "Epoch 131, Loss: 0.4492008090019226, Accuracy: 44.963314056396484\n",
            "Epoch 132, Loss: 0.4478740990161896, Accuracy: 44.833858489990234\n",
            "Epoch 133, Loss: 0.44658783078193665, Accuracy: 44.70588684082031\n",
            "Epoch 134, Loss: 0.4453064799308777, Accuracy: 44.57912826538086\n",
            "Epoch 135, Loss: 0.44405677914619446, Accuracy: 44.453548431396484\n",
            "Epoch 136, Loss: 0.44281792640686035, Accuracy: 44.3309440612793\n",
            "Epoch 137, Loss: 0.44158750772476196, Accuracy: 44.2094612121582\n",
            "Epoch 138, Loss: 0.44038087129592896, Accuracy: 44.08967971801758\n",
            "Epoch 139, Loss: 0.43923380970954895, Accuracy: 43.9710578918457\n",
            "Epoch 140, Loss: 0.4380636513233185, Accuracy: 43.85300827026367\n",
            "Epoch 141, Loss: 0.436951607465744, Accuracy: 43.73750305175781\n",
            "Epoch 142, Loss: 0.4358440041542053, Accuracy: 43.62384033203125\n",
            "Epoch 143, Loss: 0.43470385670661926, Accuracy: 43.511329650878906\n",
            "Epoch 144, Loss: 0.43365752696990967, Accuracy: 43.40018081665039\n",
            "Epoch 145, Loss: 0.4326227605342865, Accuracy: 43.29043197631836\n",
            "Epoch 146, Loss: 0.4315333366394043, Accuracy: 43.182952880859375\n",
            "Epoch 147, Loss: 0.43050679564476013, Accuracy: 43.07609939575195\n",
            "Epoch 148, Loss: 0.4294241964817047, Accuracy: 42.971248626708984\n",
            "Epoch 149, Loss: 0.42836663126945496, Accuracy: 42.86686325073242\n",
            "Epoch 150, Loss: 0.42732763290405273, Accuracy: 42.76319122314453\n",
            "Epoch 151, Loss: 0.4262717068195343, Accuracy: 42.6601676940918\n",
            "Epoch 152, Loss: 0.4252742528915405, Accuracy: 42.55869674682617\n",
            "Epoch 153, Loss: 0.42426225543022156, Accuracy: 42.46005630493164\n",
            "Epoch 154, Loss: 0.4232422113418579, Accuracy: 42.36095428466797\n",
            "Epoch 155, Loss: 0.42230087518692017, Accuracy: 42.263526916503906\n",
            "Epoch 156, Loss: 0.42131751775741577, Accuracy: 42.16659164428711\n",
            "Epoch 157, Loss: 0.42035403847694397, Accuracy: 42.07136154174805\n",
            "Epoch 158, Loss: 0.41942113637924194, Accuracy: 41.977874755859375\n",
            "Epoch 159, Loss: 0.41849470138549805, Accuracy: 41.88676834106445\n",
            "Epoch 160, Loss: 0.41759806871414185, Accuracy: 41.79437255859375\n",
            "Epoch 161, Loss: 0.4166865348815918, Accuracy: 41.70490646362305\n",
            "Epoch 162, Loss: 0.41581788659095764, Accuracy: 41.61601638793945\n",
            "Epoch 163, Loss: 0.4149138033390045, Accuracy: 41.52745056152344\n",
            "Epoch 164, Loss: 0.4140300750732422, Accuracy: 41.43952560424805\n",
            "Epoch 165, Loss: 0.41320115327835083, Accuracy: 41.351898193359375\n",
            "Epoch 166, Loss: 0.4123482406139374, Accuracy: 41.266014099121094\n",
            "Epoch 167, Loss: 0.41146883368492126, Accuracy: 41.18149185180664\n",
            "Epoch 168, Loss: 0.4106099605560303, Accuracy: 41.09676742553711\n",
            "Epoch 169, Loss: 0.4097585380077362, Accuracy: 41.01318359375\n",
            "Epoch 170, Loss: 0.40899136662483215, Accuracy: 40.931732177734375\n",
            "Epoch 171, Loss: 0.4082353711128235, Accuracy: 40.85272979736328\n",
            "Epoch 172, Loss: 0.40744608640670776, Accuracy: 40.77273178100586\n",
            "Epoch 173, Loss: 0.4066477119922638, Accuracy: 40.69313049316406\n",
            "Epoch 174, Loss: 0.40591299533843994, Accuracy: 40.61573028564453\n",
            "Epoch 175, Loss: 0.4051291346549988, Accuracy: 40.53818893432617\n",
            "Epoch 176, Loss: 0.4043363332748413, Accuracy: 40.461883544921875\n",
            "Epoch 177, Loss: 0.40359652042388916, Accuracy: 40.38551712036133\n",
            "Epoch 178, Loss: 0.4028194844722748, Accuracy: 40.30923843383789\n",
            "Epoch 179, Loss: 0.40207037329673767, Accuracy: 40.23458480834961\n",
            "Epoch 180, Loss: 0.4013151526451111, Accuracy: 40.16023635864258\n",
            "Epoch 181, Loss: 0.40057870745658875, Accuracy: 40.08608627319336\n",
            "Epoch 182, Loss: 0.3998577892780304, Accuracy: 40.0133171081543\n",
            "Epoch 183, Loss: 0.39913561940193176, Accuracy: 39.94111251831055\n",
            "Epoch 184, Loss: 0.3984563648700714, Accuracy: 39.869232177734375\n",
            "Epoch 185, Loss: 0.39774689078330994, Accuracy: 39.79912185668945\n",
            "Epoch 186, Loss: 0.3970693349838257, Accuracy: 39.728885650634766\n",
            "Epoch 187, Loss: 0.3963630497455597, Accuracy: 39.66006851196289\n",
            "Epoch 188, Loss: 0.3956514000892639, Accuracy: 39.59153747558594\n",
            "Epoch 189, Loss: 0.3949922025203705, Accuracy: 39.523284912109375\n",
            "Epoch 190, Loss: 0.3943650424480438, Accuracy: 39.45693588256836\n",
            "Epoch 191, Loss: 0.3936990797519684, Accuracy: 39.39090347290039\n",
            "Epoch 192, Loss: 0.39301514625549316, Accuracy: 39.32540512084961\n",
            "Epoch 193, Loss: 0.3923375904560089, Accuracy: 39.26006317138672\n",
            "Epoch 194, Loss: 0.3917275369167328, Accuracy: 39.19583511352539\n",
            "Epoch 195, Loss: 0.39108893275260925, Accuracy: 39.13058853149414\n",
            "Epoch 196, Loss: 0.3904423713684082, Accuracy: 39.06753158569336\n",
            "Epoch 197, Loss: 0.38986191153526306, Accuracy: 39.00467300415039\n",
            "Epoch 198, Loss: 0.3892323672771454, Accuracy: 38.94173812866211\n",
            "Epoch 199, Loss: 0.38863295316696167, Accuracy: 38.87921142578125\n",
            "Epoch 200, Loss: 0.3880078196525574, Accuracy: 38.818748474121094\n",
            "Epoch 201, Loss: 0.387448251247406, Accuracy: 38.757728576660156\n",
            "Epoch 202, Loss: 0.3868538439273834, Accuracy: 38.69816589355469\n",
            "Epoch 203, Loss: 0.38627004623413086, Accuracy: 38.639530181884766\n",
            "Epoch 204, Loss: 0.3857066333293915, Accuracy: 38.58086395263672\n",
            "Epoch 205, Loss: 0.3851982653141022, Accuracy: 38.523460388183594\n",
            "Epoch 206, Loss: 0.38460302352905273, Accuracy: 38.46601104736328\n",
            "Epoch 207, Loss: 0.3840399384498596, Accuracy: 38.40910339355469\n",
            "Epoch 208, Loss: 0.3834688365459442, Accuracy: 38.353485107421875\n",
            "Epoch 209, Loss: 0.3828924894332886, Accuracy: 38.29746627807617\n",
            "Epoch 210, Loss: 0.3823273777961731, Accuracy: 38.24204635620117\n",
            "Epoch 211, Loss: 0.38181638717651367, Accuracy: 38.18627166748047\n",
            "Epoch 212, Loss: 0.38127264380455017, Accuracy: 38.13165283203125\n",
            "Epoch 213, Loss: 0.38080406188964844, Accuracy: 38.07781982421875\n",
            "Epoch 214, Loss: 0.3802836537361145, Accuracy: 38.02370071411133\n",
            "Epoch 215, Loss: 0.3797423541545868, Accuracy: 37.970985412597656\n",
            "Epoch 216, Loss: 0.37924399971961975, Accuracy: 37.91761016845703\n",
            "Epoch 217, Loss: 0.3787122070789337, Accuracy: 37.86445236206055\n",
            "Epoch 218, Loss: 0.378194659948349, Accuracy: 37.812156677246094\n",
            "Epoch 219, Loss: 0.37779849767684937, Accuracy: 37.76173782348633\n",
            "Epoch 220, Loss: 0.3772924542427063, Accuracy: 37.71111297607422\n",
            "Epoch 221, Loss: 0.376804918050766, Accuracy: 37.65995407104492\n",
            "Epoch 222, Loss: 0.37627506256103516, Accuracy: 37.60958480834961\n",
            "Epoch 223, Loss: 0.3757858872413635, Accuracy: 37.558956146240234\n",
            "Epoch 224, Loss: 0.37529388070106506, Accuracy: 37.510581970214844\n",
            "Epoch 225, Loss: 0.3747960031032562, Accuracy: 37.46236038208008\n",
            "Epoch 226, Loss: 0.37428438663482666, Accuracy: 37.41312789916992\n",
            "Epoch 227, Loss: 0.3738277554512024, Accuracy: 37.36643600463867\n",
            "Epoch 228, Loss: 0.37334996461868286, Accuracy: 37.318851470947266\n",
            "Epoch 229, Loss: 0.37286117672920227, Accuracy: 37.271636962890625\n",
            "Epoch 230, Loss: 0.3724510669708252, Accuracy: 37.2252311706543\n",
            "Epoch 231, Loss: 0.3719950020313263, Accuracy: 37.17934036254883\n",
            "Epoch 232, Loss: 0.37151214480400085, Accuracy: 37.13239288330078\n",
            "Epoch 233, Loss: 0.37104809284210205, Accuracy: 37.0860595703125\n",
            "Epoch 234, Loss: 0.37058940529823303, Accuracy: 37.0406379699707\n",
            "Epoch 235, Loss: 0.37013158202171326, Accuracy: 36.99488067626953\n",
            "Epoch 236, Loss: 0.3696606159210205, Accuracy: 36.950164794921875\n",
            "Epoch 237, Loss: 0.36929377913475037, Accuracy: 36.9046516418457\n",
            "Epoch 238, Loss: 0.3688339293003082, Accuracy: 36.86054992675781\n",
            "Epoch 239, Loss: 0.36839020252227783, Accuracy: 36.8170051574707\n",
            "Epoch 240, Loss: 0.36794403195381165, Accuracy: 36.77311706542969\n",
            "Epoch 241, Loss: 0.36751505732536316, Accuracy: 36.72935104370117\n",
            "Epoch 242, Loss: 0.3670791685581207, Accuracy: 36.687400817871094\n",
            "Epoch 243, Loss: 0.36666029691696167, Accuracy: 36.645023345947266\n",
            "Epoch 244, Loss: 0.366243451833725, Accuracy: 36.602909088134766\n",
            "Epoch 245, Loss: 0.3658210337162018, Accuracy: 36.56172180175781\n",
            "Epoch 246, Loss: 0.3653920292854309, Accuracy: 36.52023696899414\n",
            "Epoch 247, Loss: 0.3649795651435852, Accuracy: 36.47900390625\n",
            "Epoch 248, Loss: 0.3645918071269989, Accuracy: 36.438663482666016\n",
            "Epoch 249, Loss: 0.36420613527297974, Accuracy: 36.39994430541992\n",
            "Epoch 250, Loss: 0.3638157844543457, Accuracy: 36.35984802246094\n",
            "Epoch 251, Loss: 0.3634367287158966, Accuracy: 36.32021713256836\n",
            "Epoch 252, Loss: 0.3630388677120209, Accuracy: 36.281890869140625\n",
            "Epoch 253, Loss: 0.3626544177532196, Accuracy: 36.24290084838867\n",
            "Epoch 254, Loss: 0.3622838854789734, Accuracy: 36.20364761352539\n",
            "Epoch 255, Loss: 0.36190077662467957, Accuracy: 36.16669845581055\n",
            "Epoch 256, Loss: 0.36153945326805115, Accuracy: 36.1278076171875\n",
            "Epoch 257, Loss: 0.36114755272865295, Accuracy: 36.08986282348633\n",
            "Epoch 258, Loss: 0.36079394817352295, Accuracy: 36.05230712890625\n",
            "Epoch 259, Loss: 0.3604167699813843, Accuracy: 36.01502990722656\n",
            "Epoch 260, Loss: 0.3600502014160156, Accuracy: 35.97808074951172\n",
            "Epoch 261, Loss: 0.35968297719955444, Accuracy: 35.94085693359375\n",
            "Epoch 262, Loss: 0.359341561794281, Accuracy: 35.90358352661133\n",
            "Epoch 263, Loss: 0.3589566648006439, Accuracy: 35.8671760559082\n",
            "Epoch 264, Loss: 0.3585735559463501, Accuracy: 35.83099365234375\n",
            "Epoch 265, Loss: 0.35823577642440796, Accuracy: 35.79512405395508\n",
            "Epoch 266, Loss: 0.35789358615875244, Accuracy: 35.75917434692383\n",
            "Epoch 267, Loss: 0.35753047466278076, Accuracy: 35.72365188598633\n",
            "Epoch 268, Loss: 0.35718032717704773, Accuracy: 35.68779373168945\n",
            "Epoch 269, Loss: 0.3568243980407715, Accuracy: 35.652793884277344\n",
            "Epoch 270, Loss: 0.3564717173576355, Accuracy: 35.61809158325195\n",
            "Epoch 271, Loss: 0.35613125562667847, Accuracy: 35.58317565917969\n",
            "Epoch 272, Loss: 0.35576876997947693, Accuracy: 35.549190521240234\n",
            "Epoch 273, Loss: 0.3554110527038574, Accuracy: 35.51502990722656\n",
            "Epoch 274, Loss: 0.3550803065299988, Accuracy: 35.48176956176758\n",
            "Epoch 275, Loss: 0.3547368049621582, Accuracy: 35.44765090942383\n",
            "Epoch 276, Loss: 0.3544115722179413, Accuracy: 35.4139518737793\n",
            "Epoch 277, Loss: 0.3541054129600525, Accuracy: 35.38063049316406\n",
            "Epoch 278, Loss: 0.35375407338142395, Accuracy: 35.34768295288086\n",
            "Epoch 279, Loss: 0.3534080386161804, Accuracy: 35.314483642578125\n",
            "Epoch 280, Loss: 0.3530849516391754, Accuracy: 35.28159713745117\n",
            "Epoch 281, Loss: 0.3527345359325409, Accuracy: 35.2486686706543\n",
            "Epoch 282, Loss: 0.35243719816207886, Accuracy: 35.21603775024414\n",
            "Epoch 283, Loss: 0.3521350026130676, Accuracy: 35.18362808227539\n",
            "Epoch 284, Loss: 0.35182780027389526, Accuracy: 35.1514778137207\n",
            "Epoch 285, Loss: 0.3515026867389679, Accuracy: 35.119590759277344\n",
            "Epoch 286, Loss: 0.35119011998176575, Accuracy: 35.0876350402832\n",
            "Epoch 287, Loss: 0.3508627414703369, Accuracy: 35.05640411376953\n",
            "Epoch 288, Loss: 0.3505610227584839, Accuracy: 35.02607345581055\n",
            "Epoch 289, Loss: 0.35026562213897705, Accuracy: 34.996177673339844\n",
            "Epoch 290, Loss: 0.34994974732398987, Accuracy: 34.96601486206055\n",
            "Epoch 291, Loss: 0.3496275842189789, Accuracy: 34.935672760009766\n",
            "Epoch 292, Loss: 0.34931203722953796, Accuracy: 34.90622329711914\n",
            "Epoch 293, Loss: 0.34899795055389404, Accuracy: 34.875999450683594\n",
            "Epoch 294, Loss: 0.34872549772262573, Accuracy: 34.846534729003906\n",
            "Epoch 295, Loss: 0.3484126329421997, Accuracy: 34.81682586669922\n",
            "Epoch 296, Loss: 0.3480968177318573, Accuracy: 34.78718948364258\n",
            "Epoch 297, Loss: 0.34780898690223694, Accuracy: 34.7577018737793\n",
            "Epoch 298, Loss: 0.3475128412246704, Accuracy: 34.72930908203125\n",
            "Epoch 299, Loss: 0.34722110629081726, Accuracy: 34.700538635253906\n",
            "Epoch 300, Loss: 0.346941202878952, Accuracy: 34.672306060791016\n",
            "Epoch 301, Loss: 0.34664517641067505, Accuracy: 34.64358901977539\n",
            "Epoch 302, Loss: 0.34636935591697693, Accuracy: 34.61491394042969\n",
            "Epoch 303, Loss: 0.34609776735305786, Accuracy: 34.5865592956543\n",
            "Epoch 304, Loss: 0.34580177068710327, Accuracy: 34.55827331542969\n",
            "Epoch 305, Loss: 0.3455128073692322, Accuracy: 34.529964447021484\n",
            "Epoch 306, Loss: 0.34523558616638184, Accuracy: 34.50144958496094\n",
            "Epoch 307, Loss: 0.3449776768684387, Accuracy: 34.4738883972168\n",
            "Epoch 308, Loss: 0.34472140669822693, Accuracy: 34.44669723510742\n",
            "Epoch 309, Loss: 0.3444346487522125, Accuracy: 34.419395446777344\n",
            "Epoch 310, Loss: 0.34416863322257996, Accuracy: 34.3927116394043\n",
            "Epoch 311, Loss: 0.343895822763443, Accuracy: 34.36610412597656\n",
            "Epoch 312, Loss: 0.3436104655265808, Accuracy: 34.339298248291016\n",
            "Epoch 313, Loss: 0.34332478046417236, Accuracy: 34.312477111816406\n",
            "Epoch 314, Loss: 0.34304696321487427, Accuracy: 34.28590393066406\n",
            "Epoch 315, Loss: 0.34278547763824463, Accuracy: 34.25947189331055\n",
            "Epoch 316, Loss: 0.3425430953502655, Accuracy: 34.23414993286133\n",
            "Epoch 317, Loss: 0.34228065609931946, Accuracy: 34.20777130126953\n",
            "Epoch 318, Loss: 0.34205880761146545, Accuracy: 34.182918548583984\n",
            "Epoch 319, Loss: 0.3417947292327881, Accuracy: 34.1570930480957\n",
            "Epoch 320, Loss: 0.34153157472610474, Accuracy: 34.131858825683594\n",
            "Epoch 321, Loss: 0.34126678109169006, Accuracy: 34.106380462646484\n",
            "Epoch 322, Loss: 0.3410041630268097, Accuracy: 34.08198547363281\n",
            "Epoch 323, Loss: 0.3407543897628784, Accuracy: 34.05669403076172\n",
            "Epoch 324, Loss: 0.340506911277771, Accuracy: 34.03154754638672\n",
            "Epoch 325, Loss: 0.34024539589881897, Accuracy: 34.00678253173828\n",
            "Epoch 326, Loss: 0.3400155305862427, Accuracy: 33.98314666748047\n",
            "Epoch 327, Loss: 0.3398262858390808, Accuracy: 33.959205627441406\n",
            "Epoch 328, Loss: 0.33960968255996704, Accuracy: 33.93555450439453\n",
            "Epoch 329, Loss: 0.3393518030643463, Accuracy: 33.91101837158203\n",
            "Epoch 330, Loss: 0.3391071557998657, Accuracy: 33.88648223876953\n",
            "Epoch 331, Loss: 0.3388834297657013, Accuracy: 33.862327575683594\n",
            "Epoch 332, Loss: 0.33865752816200256, Accuracy: 33.83926010131836\n",
            "Epoch 333, Loss: 0.33840903639793396, Accuracy: 33.815486907958984\n",
            "Epoch 334, Loss: 0.33815428614616394, Accuracy: 33.791751861572266\n",
            "Epoch 335, Loss: 0.33792009949684143, Accuracy: 33.76869583129883\n",
            "Epoch 336, Loss: 0.3376798629760742, Accuracy: 33.745296478271484\n",
            "Epoch 337, Loss: 0.337431937456131, Accuracy: 33.72199249267578\n",
            "Epoch 338, Loss: 0.33719295263290405, Accuracy: 33.69927978515625\n",
            "Epoch 339, Loss: 0.33695727586746216, Accuracy: 33.67611312866211\n",
            "Epoch 340, Loss: 0.33674660325050354, Accuracy: 33.653663635253906\n",
            "Epoch 341, Loss: 0.336513489484787, Accuracy: 33.63066101074219\n",
            "Epoch 342, Loss: 0.3362807333469391, Accuracy: 33.60841369628906\n",
            "Epoch 343, Loss: 0.3360470235347748, Accuracy: 33.586334228515625\n",
            "Epoch 344, Loss: 0.3358357846736908, Accuracy: 33.56399154663086\n",
            "Epoch 345, Loss: 0.3356040418148041, Accuracy: 33.54197311401367\n",
            "Epoch 346, Loss: 0.3353763818740845, Accuracy: 33.519630432128906\n",
            "Epoch 347, Loss: 0.33516746759414673, Accuracy: 33.49807357788086\n",
            "Epoch 348, Loss: 0.33496612310409546, Accuracy: 33.476959228515625\n",
            "Epoch 349, Loss: 0.3347771465778351, Accuracy: 33.455692291259766\n",
            "Epoch 350, Loss: 0.3345915973186493, Accuracy: 33.434669494628906\n",
            "Epoch 351, Loss: 0.33437496423721313, Accuracy: 33.41293716430664\n",
            "Epoch 352, Loss: 0.3341583013534546, Accuracy: 33.3914680480957\n",
            "Epoch 353, Loss: 0.3339325487613678, Accuracy: 33.369842529296875\n",
            "Epoch 354, Loss: 0.33370834589004517, Accuracy: 33.34870910644531\n",
            "Epoch 355, Loss: 0.33348652720451355, Accuracy: 33.32744598388672\n",
            "Epoch 356, Loss: 0.3332673907279968, Accuracy: 33.306087493896484\n",
            "Epoch 357, Loss: 0.3330968916416168, Accuracy: 33.28573226928711\n",
            "Epoch 358, Loss: 0.33289504051208496, Accuracy: 33.26606369018555\n",
            "Epoch 359, Loss: 0.3326810300350189, Accuracy: 33.245750427246094\n",
            "Epoch 360, Loss: 0.33248981833457947, Accuracy: 33.22550964355469\n",
            "Epoch 361, Loss: 0.33228030800819397, Accuracy: 33.20561599731445\n",
            "Epoch 362, Loss: 0.33209341764450073, Accuracy: 33.185306549072266\n",
            "Epoch 363, Loss: 0.3319173753261566, Accuracy: 33.165069580078125\n",
            "Epoch 364, Loss: 0.33170461654663086, Accuracy: 33.14497375488281\n",
            "Epoch 365, Loss: 0.33151179552078247, Accuracy: 33.12483596801758\n",
            "Epoch 366, Loss: 0.3313171863555908, Accuracy: 33.104835510253906\n",
            "Epoch 367, Loss: 0.3311268985271454, Accuracy: 33.084938049316406\n",
            "Epoch 368, Loss: 0.3309164345264435, Accuracy: 33.06538391113281\n",
            "Epoch 369, Loss: 0.3307071626186371, Accuracy: 33.04563903808594\n",
            "Epoch 370, Loss: 0.3305014967918396, Accuracy: 33.026268005371094\n",
            "Epoch 371, Loss: 0.3303058445453644, Accuracy: 33.00713348388672\n",
            "Epoch 372, Loss: 0.330105721950531, Accuracy: 32.987770080566406\n",
            "Epoch 373, Loss: 0.3299490511417389, Accuracy: 32.96854782104492\n",
            "Epoch 374, Loss: 0.3297877311706543, Accuracy: 32.9504508972168\n",
            "Epoch 375, Loss: 0.3295964002609253, Accuracy: 32.931392669677734\n",
            "Epoch 376, Loss: 0.3294031620025635, Accuracy: 32.91240692138672\n",
            "Epoch 377, Loss: 0.32921886444091797, Accuracy: 32.893646240234375\n",
            "Epoch 378, Loss: 0.32903167605400085, Accuracy: 32.87493133544922\n",
            "Epoch 379, Loss: 0.3288329243659973, Accuracy: 32.856109619140625\n",
            "Epoch 380, Loss: 0.32866600155830383, Accuracy: 32.83830261230469\n",
            "Epoch 381, Loss: 0.3285121023654938, Accuracy: 32.82032012939453\n",
            "Epoch 382, Loss: 0.3283323049545288, Accuracy: 32.802093505859375\n",
            "Epoch 383, Loss: 0.32816341519355774, Accuracy: 32.78375244140625\n",
            "Epoch 384, Loss: 0.32797056436538696, Accuracy: 32.765464782714844\n",
            "Epoch 385, Loss: 0.32779696583747864, Accuracy: 32.74740982055664\n",
            "Epoch 386, Loss: 0.3276083469390869, Accuracy: 32.72991943359375\n",
            "Epoch 387, Loss: 0.32744142413139343, Accuracy: 32.711727142333984\n",
            "Epoch 388, Loss: 0.3272705376148224, Accuracy: 32.693702697753906\n",
            "Epoch 389, Loss: 0.32709500193595886, Accuracy: 32.67576217651367\n",
            "Epoch 390, Loss: 0.3269018530845642, Accuracy: 32.65763473510742\n",
            "Epoch 391, Loss: 0.3267160654067993, Accuracy: 32.6400146484375\n",
            "Epoch 392, Loss: 0.3265434205532074, Accuracy: 32.623191833496094\n",
            "Epoch 393, Loss: 0.32636356353759766, Accuracy: 32.606285095214844\n",
            "Epoch 394, Loss: 0.32618826627731323, Accuracy: 32.588951110839844\n",
            "Epoch 395, Loss: 0.32600581645965576, Accuracy: 32.57173538208008\n",
            "Epoch 396, Loss: 0.32584744691848755, Accuracy: 32.554237365722656\n",
            "Epoch 397, Loss: 0.32567298412323, Accuracy: 32.537208557128906\n",
            "Epoch 398, Loss: 0.32551509141921997, Accuracy: 32.52083206176758\n",
            "Epoch 399, Loss: 0.3253312408924103, Accuracy: 32.50386428833008\n",
            "Epoch 400, Loss: 0.3251720368862152, Accuracy: 32.48701858520508\n",
            "Epoch 401, Loss: 0.32498762011528015, Accuracy: 32.47004318237305\n",
            "Epoch 402, Loss: 0.324826717376709, Accuracy: 32.45330047607422\n",
            "Epoch 403, Loss: 0.3246608078479767, Accuracy: 32.43634033203125\n",
            "Epoch 404, Loss: 0.32448625564575195, Accuracy: 32.420230865478516\n",
            "Epoch 405, Loss: 0.32430729269981384, Accuracy: 32.403568267822266\n",
            "Epoch 406, Loss: 0.32413384318351746, Accuracy: 32.38707733154297\n",
            "Epoch 407, Loss: 0.3239816129207611, Accuracy: 32.370845794677734\n",
            "Epoch 408, Loss: 0.3238191306591034, Accuracy: 32.354976654052734\n",
            "Epoch 409, Loss: 0.32364407181739807, Accuracy: 32.33847427368164\n",
            "Epoch 410, Loss: 0.3235100209712982, Accuracy: 32.322505950927734\n",
            "Epoch 411, Loss: 0.3233628571033478, Accuracy: 32.306541442871094\n",
            "Epoch 412, Loss: 0.32319992780685425, Accuracy: 32.29084777832031\n",
            "Epoch 413, Loss: 0.3230394124984741, Accuracy: 32.275997161865234\n",
            "Epoch 414, Loss: 0.3228960633277893, Accuracy: 32.26020050048828\n",
            "Epoch 415, Loss: 0.3227275311946869, Accuracy: 32.244022369384766\n",
            "Epoch 416, Loss: 0.32256266474723816, Accuracy: 32.228477478027344\n",
            "Epoch 417, Loss: 0.32240891456604004, Accuracy: 32.212974548339844\n",
            "Epoch 418, Loss: 0.3222517967224121, Accuracy: 32.19749069213867\n",
            "Epoch 419, Loss: 0.3221036195755005, Accuracy: 32.182430267333984\n",
            "Epoch 420, Loss: 0.3219524919986725, Accuracy: 32.16712951660156\n",
            "Epoch 421, Loss: 0.32182711362838745, Accuracy: 32.15176010131836\n",
            "Epoch 422, Loss: 0.32166314125061035, Accuracy: 32.136661529541016\n",
            "Epoch 423, Loss: 0.3215444087982178, Accuracy: 32.12158966064453\n",
            "Epoch 424, Loss: 0.3214075267314911, Accuracy: 32.10695266723633\n",
            "Epoch 425, Loss: 0.3213024437427521, Accuracy: 32.09234619140625\n",
            "Epoch 426, Loss: 0.3211517930030823, Accuracy: 32.07820510864258\n",
            "Epoch 427, Loss: 0.3209872245788574, Accuracy: 32.063148498535156\n",
            "Epoch 428, Loss: 0.3208220899105072, Accuracy: 32.04805374145508\n",
            "Epoch 429, Loss: 0.3206722140312195, Accuracy: 32.0334587097168\n",
            "Epoch 430, Loss: 0.32051315903663635, Accuracy: 32.01893615722656\n",
            "Epoch 431, Loss: 0.3203754127025604, Accuracy: 32.00456619262695\n",
            "Epoch 432, Loss: 0.32023271918296814, Accuracy: 31.99005126953125\n",
            "Epoch 433, Loss: 0.32008084654808044, Accuracy: 31.975608825683594\n",
            "Epoch 434, Loss: 0.31992533802986145, Accuracy: 31.960847854614258\n",
            "Epoch 435, Loss: 0.31980055570602417, Accuracy: 31.946744918823242\n",
            "Epoch 436, Loss: 0.3196667730808258, Accuracy: 31.932649612426758\n",
            "Epoch 437, Loss: 0.319522887468338, Accuracy: 31.918519973754883\n",
            "Epoch 438, Loss: 0.31938132643699646, Accuracy: 31.90467071533203\n",
            "Epoch 439, Loss: 0.31923308968544006, Accuracy: 31.890838623046875\n",
            "Epoch 440, Loss: 0.3190925121307373, Accuracy: 31.877254486083984\n",
            "Epoch 441, Loss: 0.3189685642719269, Accuracy: 31.863534927368164\n",
            "Epoch 442, Loss: 0.3188471496105194, Accuracy: 31.849584579467773\n",
            "Epoch 443, Loss: 0.3187098801136017, Accuracy: 31.835317611694336\n",
            "Epoch 444, Loss: 0.31857869029045105, Accuracy: 31.82176399230957\n",
            "Epoch 445, Loss: 0.31844472885131836, Accuracy: 31.808046340942383\n",
            "Epoch 446, Loss: 0.3183005750179291, Accuracy: 31.794601440429688\n",
            "Epoch 447, Loss: 0.3181609809398651, Accuracy: 31.78139305114746\n",
            "Epoch 448, Loss: 0.31801289319992065, Accuracy: 31.767406463623047\n",
            "Epoch 449, Loss: 0.31787100434303284, Accuracy: 31.753551483154297\n",
            "Epoch 450, Loss: 0.31772246956825256, Accuracy: 31.73992919921875\n",
            "Epoch 451, Loss: 0.31757375597953796, Accuracy: 31.72637176513672\n",
            "Epoch 452, Loss: 0.31742748618125916, Accuracy: 31.712717056274414\n",
            "Epoch 453, Loss: 0.3172883987426758, Accuracy: 31.69927978515625\n",
            "Epoch 454, Loss: 0.31714269518852234, Accuracy: 31.685760498046875\n",
            "Epoch 455, Loss: 0.31700485944747925, Accuracy: 31.672576904296875\n",
            "Epoch 456, Loss: 0.31687211990356445, Accuracy: 31.65963363647461\n",
            "Epoch 457, Loss: 0.31673523783683777, Accuracy: 31.6466007232666\n",
            "Epoch 458, Loss: 0.3165898025035858, Accuracy: 31.63328742980957\n",
            "Epoch 459, Loss: 0.31648021936416626, Accuracy: 31.619956970214844\n",
            "Epoch 460, Loss: 0.31634268164634705, Accuracy: 31.606897354125977\n",
            "Epoch 461, Loss: 0.3162305951118469, Accuracy: 31.59415054321289\n",
            "Epoch 462, Loss: 0.3161175847053528, Accuracy: 31.581867218017578\n",
            "Epoch 463, Loss: 0.31600382924079895, Accuracy: 31.568798065185547\n",
            "Epoch 464, Loss: 0.31589338183403015, Accuracy: 31.555906295776367\n",
            "Epoch 465, Loss: 0.31576746702194214, Accuracy: 31.543678283691406\n",
            "Epoch 466, Loss: 0.31564751267433167, Accuracy: 31.53152084350586\n",
            "Epoch 467, Loss: 0.315524697303772, Accuracy: 31.51972007751465\n",
            "Epoch 468, Loss: 0.3153974115848541, Accuracy: 31.507083892822266\n",
            "Epoch 469, Loss: 0.3152618408203125, Accuracy: 31.494449615478516\n",
            "Epoch 470, Loss: 0.31515443325042725, Accuracy: 31.481903076171875\n",
            "Epoch 471, Loss: 0.31502336263656616, Accuracy: 31.469738006591797\n",
            "Epoch 472, Loss: 0.31489652395248413, Accuracy: 31.457345962524414\n",
            "Epoch 473, Loss: 0.31478142738342285, Accuracy: 31.44489288330078\n",
            "Epoch 474, Loss: 0.31466570496559143, Accuracy: 31.4330997467041\n",
            "Epoch 475, Loss: 0.3145325779914856, Accuracy: 31.420743942260742\n",
            "Epoch 476, Loss: 0.31441015005111694, Accuracy: 31.408584594726562\n",
            "Epoch 477, Loss: 0.31429117918014526, Accuracy: 31.396154403686523\n",
            "Epoch 478, Loss: 0.3141654431819916, Accuracy: 31.384103775024414\n",
            "Epoch 479, Loss: 0.31404244899749756, Accuracy: 31.371997833251953\n",
            "Epoch 480, Loss: 0.3139110803604126, Accuracy: 31.3596248626709\n",
            "Epoch 481, Loss: 0.31379440426826477, Accuracy: 31.347578048706055\n",
            "Epoch 482, Loss: 0.3136683404445648, Accuracy: 31.33554458618164\n",
            "Epoch 483, Loss: 0.3135439157485962, Accuracy: 31.323715209960938\n",
            "Epoch 484, Loss: 0.3134154975414276, Accuracy: 31.31192398071289\n",
            "Epoch 485, Loss: 0.3132868707180023, Accuracy: 31.29991340637207\n",
            "Epoch 486, Loss: 0.3131580948829651, Accuracy: 31.28824234008789\n",
            "Epoch 487, Loss: 0.3130357563495636, Accuracy: 31.276412963867188\n",
            "Epoch 488, Loss: 0.3129134178161621, Accuracy: 31.264751434326172\n",
            "Epoch 489, Loss: 0.31279823184013367, Accuracy: 31.25356101989746\n",
            "Epoch 490, Loss: 0.31268027424812317, Accuracy: 31.242019653320312\n",
            "Epoch 491, Loss: 0.3125557601451874, Accuracy: 31.230159759521484\n",
            "Epoch 492, Loss: 0.31244373321533203, Accuracy: 31.21880531311035\n",
            "Epoch 493, Loss: 0.3123305141925812, Accuracy: 31.2077579498291\n",
            "Epoch 494, Loss: 0.3122389018535614, Accuracy: 31.19634437561035\n",
            "Epoch 495, Loss: 0.3121183216571808, Accuracy: 31.184873580932617\n",
            "Epoch 496, Loss: 0.3119984269142151, Accuracy: 31.173389434814453\n",
            "Epoch 497, Loss: 0.31189030408859253, Accuracy: 31.162002563476562\n",
            "Epoch 498, Loss: 0.31176555156707764, Accuracy: 31.150632858276367\n",
            "Epoch 499, Loss: 0.3116593062877655, Accuracy: 31.13965606689453\n",
            "Epoch 500, Loss: 0.31154054403305054, Accuracy: 31.128936767578125\n",
            "Epoch 501, Loss: 0.31142500042915344, Accuracy: 31.117820739746094\n",
            "Epoch 502, Loss: 0.3113132119178772, Accuracy: 31.106761932373047\n",
            "Epoch 503, Loss: 0.31120988726615906, Accuracy: 31.095949172973633\n",
            "Epoch 504, Loss: 0.31109699606895447, Accuracy: 31.085416793823242\n",
            "Epoch 505, Loss: 0.3110086917877197, Accuracy: 31.07452964782715\n",
            "Epoch 506, Loss: 0.3108900189399719, Accuracy: 31.0638484954834\n",
            "Epoch 507, Loss: 0.31077298521995544, Accuracy: 31.053268432617188\n",
            "Epoch 508, Loss: 0.3106633722782135, Accuracy: 31.04248046875\n",
            "Epoch 509, Loss: 0.31054532527923584, Accuracy: 31.031721115112305\n",
            "Epoch 510, Loss: 0.31044280529022217, Accuracy: 31.021373748779297\n",
            "Epoch 511, Loss: 0.3103238344192505, Accuracy: 31.01038932800293\n",
            "Epoch 512, Loss: 0.31021857261657715, Accuracy: 30.999649047851562\n",
            "Epoch 513, Loss: 0.31010305881500244, Accuracy: 30.98922348022461\n",
            "Epoch 514, Loss: 0.3100166916847229, Accuracy: 30.978378295898438\n",
            "Epoch 515, Loss: 0.30991312861442566, Accuracy: 30.96833610534668\n",
            "Epoch 516, Loss: 0.30979910492897034, Accuracy: 30.95760726928711\n",
            "Epoch 517, Loss: 0.30970823764801025, Accuracy: 30.946990966796875\n",
            "Epoch 518, Loss: 0.3096100687980652, Accuracy: 30.936458587646484\n",
            "Epoch 519, Loss: 0.30949488282203674, Accuracy: 30.926069259643555\n",
            "Epoch 520, Loss: 0.30940067768096924, Accuracy: 30.915891647338867\n",
            "Epoch 521, Loss: 0.3092862367630005, Accuracy: 30.905363082885742\n",
            "Epoch 522, Loss: 0.3091708719730377, Accuracy: 30.894744873046875\n",
            "Epoch 523, Loss: 0.3090730309486389, Accuracy: 30.88459014892578\n",
            "Epoch 524, Loss: 0.3089620769023895, Accuracy: 30.874406814575195\n",
            "Epoch 525, Loss: 0.30884483456611633, Accuracy: 30.863842010498047\n",
            "Epoch 526, Loss: 0.3087342381477356, Accuracy: 30.85368537902832\n",
            "Epoch 527, Loss: 0.30863234400749207, Accuracy: 30.843765258789062\n",
            "Epoch 528, Loss: 0.308551549911499, Accuracy: 30.833669662475586\n",
            "Epoch 529, Loss: 0.30845364928245544, Accuracy: 30.823692321777344\n",
            "Epoch 530, Loss: 0.3083822429180145, Accuracy: 30.813932418823242\n",
            "Epoch 531, Loss: 0.3082788586616516, Accuracy: 30.803817749023438\n",
            "Epoch 532, Loss: 0.3081906735897064, Accuracy: 30.79440689086914\n",
            "Epoch 533, Loss: 0.30809125304222107, Accuracy: 30.78467559814453\n",
            "Epoch 534, Loss: 0.30802658200263977, Accuracy: 30.77520751953125\n",
            "Epoch 535, Loss: 0.3079339265823364, Accuracy: 30.76578140258789\n",
            "Epoch 536, Loss: 0.3078474998474121, Accuracy: 30.75635528564453\n",
            "Epoch 537, Loss: 0.3077511489391327, Accuracy: 30.74662971496582\n",
            "Epoch 538, Loss: 0.3076450824737549, Accuracy: 30.736953735351562\n",
            "Epoch 539, Loss: 0.3075504004955292, Accuracy: 30.72715950012207\n",
            "Epoch 540, Loss: 0.3074526786804199, Accuracy: 30.717533111572266\n",
            "Epoch 541, Loss: 0.3073546886444092, Accuracy: 30.70784568786621\n",
            "Epoch 542, Loss: 0.3072577118873596, Accuracy: 30.69866371154785\n",
            "Epoch 543, Loss: 0.30716222524642944, Accuracy: 30.688840866088867\n",
            "Epoch 544, Loss: 0.30706435441970825, Accuracy: 30.679407119750977\n",
            "Epoch 545, Loss: 0.3069615960121155, Accuracy: 30.670034408569336\n",
            "Epoch 546, Loss: 0.306855171918869, Accuracy: 30.66050148010254\n",
            "Epoch 547, Loss: 0.3067713975906372, Accuracy: 30.651165008544922\n",
            "Epoch 548, Loss: 0.30668407678604126, Accuracy: 30.64196014404297\n",
            "Epoch 549, Loss: 0.3065926134586334, Accuracy: 30.63272476196289\n",
            "Epoch 550, Loss: 0.3065158724784851, Accuracy: 30.623510360717773\n",
            "Epoch 551, Loss: 0.3064180314540863, Accuracy: 30.614593505859375\n",
            "Epoch 552, Loss: 0.3063207268714905, Accuracy: 30.60536766052246\n",
            "Epoch 553, Loss: 0.3062152564525604, Accuracy: 30.595794677734375\n",
            "Epoch 554, Loss: 0.30611464381217957, Accuracy: 30.58655548095703\n",
            "Epoch 555, Loss: 0.30601561069488525, Accuracy: 30.57742691040039\n",
            "Epoch 556, Loss: 0.30591902136802673, Accuracy: 30.568754196166992\n",
            "Epoch 557, Loss: 0.30583614110946655, Accuracy: 30.5596866607666\n",
            "Epoch 558, Loss: 0.3057423532009125, Accuracy: 30.550798416137695\n",
            "Epoch 559, Loss: 0.3056493103504181, Accuracy: 30.541810989379883\n",
            "Epoch 560, Loss: 0.3055581748485565, Accuracy: 30.532535552978516\n",
            "Epoch 561, Loss: 0.30546247959136963, Accuracy: 30.523386001586914\n",
            "Epoch 562, Loss: 0.30538031458854675, Accuracy: 30.5148868560791\n",
            "Epoch 563, Loss: 0.3052932322025299, Accuracy: 30.507070541381836\n",
            "Epoch 564, Loss: 0.3052002787590027, Accuracy: 30.498132705688477\n",
            "Epoch 565, Loss: 0.3051092028617859, Accuracy: 30.48936653137207\n",
            "Epoch 566, Loss: 0.30501455068588257, Accuracy: 30.48056411743164\n",
            "Epoch 567, Loss: 0.3049353361129761, Accuracy: 30.471574783325195\n",
            "Epoch 568, Loss: 0.304837167263031, Accuracy: 30.462646484375\n",
            "Epoch 569, Loss: 0.30476364493370056, Accuracy: 30.45412826538086\n",
            "Epoch 570, Loss: 0.3046863079071045, Accuracy: 30.445606231689453\n",
            "Epoch 571, Loss: 0.3046003580093384, Accuracy: 30.436649322509766\n",
            "Epoch 572, Loss: 0.3045029640197754, Accuracy: 30.427783966064453\n",
            "Epoch 573, Loss: 0.30440589785575867, Accuracy: 30.418994903564453\n",
            "Epoch 574, Loss: 0.3043324649333954, Accuracy: 30.409961700439453\n",
            "Epoch 575, Loss: 0.304264098405838, Accuracy: 30.401914596557617\n",
            "Epoch 576, Loss: 0.3041868507862091, Accuracy: 30.39388656616211\n",
            "Epoch 577, Loss: 0.3041094243526459, Accuracy: 30.385292053222656\n",
            "Epoch 578, Loss: 0.3040330708026886, Accuracy: 30.376678466796875\n",
            "Epoch 579, Loss: 0.30394816398620605, Accuracy: 30.367895126342773\n",
            "Epoch 580, Loss: 0.30386319756507874, Accuracy: 30.3593692779541\n",
            "Epoch 581, Loss: 0.3037709891796112, Accuracy: 30.350765228271484\n",
            "Epoch 582, Loss: 0.3036770224571228, Accuracy: 30.342058181762695\n",
            "Epoch 583, Loss: 0.3036130964756012, Accuracy: 30.333364486694336\n",
            "Epoch 584, Loss: 0.30352404713630676, Accuracy: 30.325450897216797\n",
            "Epoch 585, Loss: 0.3034396171569824, Accuracy: 30.31686782836914\n",
            "Epoch 586, Loss: 0.30334705114364624, Accuracy: 30.308481216430664\n",
            "Epoch 587, Loss: 0.3032597005367279, Accuracy: 30.300140380859375\n",
            "Epoch 588, Loss: 0.30317604541778564, Accuracy: 30.29241943359375\n",
            "Epoch 589, Loss: 0.303091436624527, Accuracy: 30.283897399902344\n",
            "Epoch 590, Loss: 0.3030126392841339, Accuracy: 30.275312423706055\n",
            "Epoch 591, Loss: 0.30292704701423645, Accuracy: 30.267223358154297\n",
            "Epoch 592, Loss: 0.30284443497657776, Accuracy: 30.259422302246094\n",
            "Epoch 593, Loss: 0.3027559816837311, Accuracy: 30.2509822845459\n",
            "Epoch 594, Loss: 0.30266597867012024, Accuracy: 30.243011474609375\n",
            "Epoch 595, Loss: 0.3025774657726288, Accuracy: 30.235034942626953\n",
            "Epoch 596, Loss: 0.30248579382896423, Accuracy: 30.22679901123047\n",
            "Epoch 597, Loss: 0.3023950755596161, Accuracy: 30.218542098999023\n",
            "Epoch 598, Loss: 0.30230531096458435, Accuracy: 30.21015167236328\n",
            "Epoch 599, Loss: 0.30221548676490784, Accuracy: 30.20191192626953\n",
            "Epoch 600, Loss: 0.3021250367164612, Accuracy: 30.193828582763672\n",
            "Epoch 601, Loss: 0.30205026268959045, Accuracy: 30.185544967651367\n",
            "Epoch 602, Loss: 0.30196720361709595, Accuracy: 30.177614212036133\n",
            "Epoch 603, Loss: 0.3018849194049835, Accuracy: 30.169544219970703\n",
            "Epoch 604, Loss: 0.3018118739128113, Accuracy: 30.161418914794922\n",
            "Epoch 605, Loss: 0.3017254173755646, Accuracy: 30.15316390991211\n",
            "Epoch 606, Loss: 0.30163809657096863, Accuracy: 30.14512062072754\n",
            "Epoch 607, Loss: 0.30155277252197266, Accuracy: 30.137380599975586\n",
            "Epoch 608, Loss: 0.3014635145664215, Accuracy: 30.129364013671875\n",
            "Epoch 609, Loss: 0.3013806641101837, Accuracy: 30.121349334716797\n",
            "Epoch 610, Loss: 0.301318496465683, Accuracy: 30.11346435546875\n",
            "Epoch 611, Loss: 0.30124056339263916, Accuracy: 30.105422973632812\n",
            "Epoch 612, Loss: 0.30115431547164917, Accuracy: 30.097631454467773\n",
            "Epoch 613, Loss: 0.3010822832584381, Accuracy: 30.089839935302734\n",
            "Epoch 614, Loss: 0.30100035667419434, Accuracy: 30.082326889038086\n",
            "Epoch 615, Loss: 0.3009289503097534, Accuracy: 30.075016021728516\n",
            "Epoch 616, Loss: 0.3008574843406677, Accuracy: 30.067285537719727\n",
            "Epoch 617, Loss: 0.300774484872818, Accuracy: 30.059579849243164\n",
            "Epoch 618, Loss: 0.3007124364376068, Accuracy: 30.051973342895508\n",
            "Epoch 619, Loss: 0.30063530802726746, Accuracy: 30.044958114624023\n",
            "Epoch 620, Loss: 0.3005540072917938, Accuracy: 30.03734588623047\n",
            "Epoch 621, Loss: 0.30049532651901245, Accuracy: 30.029970169067383\n",
            "Epoch 622, Loss: 0.30040988326072693, Accuracy: 30.022123336791992\n",
            "Epoch 623, Loss: 0.30034032464027405, Accuracy: 30.01459312438965\n",
            "Epoch 624, Loss: 0.30025529861450195, Accuracy: 30.00698471069336\n",
            "Epoch 625, Loss: 0.3001967966556549, Accuracy: 29.999324798583984\n",
            "Epoch 626, Loss: 0.30011239647865295, Accuracy: 29.991844177246094\n",
            "Epoch 627, Loss: 0.3000507950782776, Accuracy: 29.984172821044922\n",
            "Epoch 628, Loss: 0.29997628927230835, Accuracy: 29.976591110229492\n",
            "Epoch 629, Loss: 0.2999105751514435, Accuracy: 29.96893882751465\n",
            "Epoch 630, Loss: 0.29984191060066223, Accuracy: 29.961761474609375\n",
            "Epoch 631, Loss: 0.29976844787597656, Accuracy: 29.95418930053711\n",
            "Epoch 632, Loss: 0.29968956112861633, Accuracy: 29.947078704833984\n",
            "Epoch 633, Loss: 0.29961055517196655, Accuracy: 29.939741134643555\n",
            "Epoch 634, Loss: 0.29955124855041504, Accuracy: 29.932598114013672\n",
            "Epoch 635, Loss: 0.29947736859321594, Accuracy: 29.925294876098633\n",
            "Epoch 636, Loss: 0.29940152168273926, Accuracy: 29.918336868286133\n",
            "Epoch 637, Loss: 0.2993381917476654, Accuracy: 29.91132164001465\n",
            "Epoch 638, Loss: 0.2992720305919647, Accuracy: 29.904333114624023\n",
            "Epoch 639, Loss: 0.29920223355293274, Accuracy: 29.897249221801758\n",
            "Epoch 640, Loss: 0.2991240620613098, Accuracy: 29.88992691040039\n",
            "Epoch 641, Loss: 0.29905128479003906, Accuracy: 29.883121490478516\n",
            "Epoch 642, Loss: 0.29897549748420715, Accuracy: 29.876100540161133\n",
            "Epoch 643, Loss: 0.29890722036361694, Accuracy: 29.869091033935547\n",
            "Epoch 644, Loss: 0.29883620142936707, Accuracy: 29.862140655517578\n",
            "Epoch 645, Loss: 0.2987646758556366, Accuracy: 29.855337142944336\n",
            "Epoch 646, Loss: 0.29870298504829407, Accuracy: 29.84839630126953\n",
            "Epoch 647, Loss: 0.29864075779914856, Accuracy: 29.841379165649414\n",
            "Epoch 648, Loss: 0.29855984449386597, Accuracy: 29.834102630615234\n",
            "Epoch 649, Loss: 0.298492431640625, Accuracy: 29.82705307006836\n",
            "Epoch 650, Loss: 0.29842108488082886, Accuracy: 29.81976318359375\n",
            "Epoch 651, Loss: 0.2983470559120178, Accuracy: 29.81269073486328\n",
            "Epoch 652, Loss: 0.2982730269432068, Accuracy: 29.80558204650879\n",
            "Epoch 653, Loss: 0.2982015907764435, Accuracy: 29.798612594604492\n",
            "Epoch 654, Loss: 0.29813212156295776, Accuracy: 29.791736602783203\n",
            "Epoch 655, Loss: 0.2980620563030243, Accuracy: 29.784879684448242\n",
            "Epoch 656, Loss: 0.2979878783226013, Accuracy: 29.778121948242188\n",
            "Epoch 657, Loss: 0.29791346192359924, Accuracy: 29.771459579467773\n",
            "Epoch 658, Loss: 0.2978418171405792, Accuracy: 29.76460075378418\n",
            "Epoch 659, Loss: 0.29776543378829956, Accuracy: 29.757808685302734\n",
            "Epoch 660, Loss: 0.29769161343574524, Accuracy: 29.750886917114258\n",
            "Epoch 661, Loss: 0.29762566089630127, Accuracy: 29.744253158569336\n",
            "Epoch 662, Loss: 0.2975653111934662, Accuracy: 29.737653732299805\n",
            "Epoch 663, Loss: 0.2974960207939148, Accuracy: 29.731359481811523\n",
            "Epoch 664, Loss: 0.29741916060447693, Accuracy: 29.72455596923828\n",
            "Epoch 665, Loss: 0.2973444163799286, Accuracy: 29.717849731445312\n",
            "Epoch 666, Loss: 0.2972713112831116, Accuracy: 29.71087074279785\n",
            "Epoch 667, Loss: 0.2972014248371124, Accuracy: 29.70392417907715\n",
            "Epoch 668, Loss: 0.29713788628578186, Accuracy: 29.697486877441406\n",
            "Epoch 669, Loss: 0.2970772385597229, Accuracy: 29.69118881225586\n",
            "Epoch 670, Loss: 0.297004371881485, Accuracy: 29.684659957885742\n",
            "Epoch 671, Loss: 0.2969513237476349, Accuracy: 29.677852630615234\n",
            "Epoch 672, Loss: 0.2968886196613312, Accuracy: 29.671398162841797\n",
            "Epoch 673, Loss: 0.29683244228363037, Accuracy: 29.66473388671875\n",
            "Epoch 674, Loss: 0.2967642545700073, Accuracy: 29.658519744873047\n",
            "Epoch 675, Loss: 0.2966915965080261, Accuracy: 29.65189552307129\n",
            "Epoch 676, Loss: 0.2966327369213104, Accuracy: 29.64509391784668\n",
            "Epoch 677, Loss: 0.2965722978115082, Accuracy: 29.638525009155273\n",
            "Epoch 678, Loss: 0.29651638865470886, Accuracy: 29.632165908813477\n",
            "Epoch 679, Loss: 0.2964506447315216, Accuracy: 29.62574577331543\n",
            "Epoch 680, Loss: 0.29638195037841797, Accuracy: 29.619144439697266\n",
            "Epoch 681, Loss: 0.29632067680358887, Accuracy: 29.61290168762207\n",
            "Epoch 682, Loss: 0.29624900221824646, Accuracy: 29.606616973876953\n",
            "Epoch 683, Loss: 0.29619285464286804, Accuracy: 29.600223541259766\n",
            "Epoch 684, Loss: 0.2961322069168091, Accuracy: 29.593765258789062\n",
            "Epoch 685, Loss: 0.2960716784000397, Accuracy: 29.5874080657959\n",
            "Epoch 686, Loss: 0.2960202991962433, Accuracy: 29.581249237060547\n",
            "Epoch 687, Loss: 0.2959558665752411, Accuracy: 29.574474334716797\n",
            "Epoch 688, Loss: 0.2958917021751404, Accuracy: 29.568368911743164\n",
            "Epoch 689, Loss: 0.2958449423313141, Accuracy: 29.56186294555664\n",
            "Epoch 690, Loss: 0.295772910118103, Accuracy: 29.55536460876465\n",
            "Epoch 691, Loss: 0.29570430517196655, Accuracy: 29.54926109313965\n",
            "Epoch 692, Loss: 0.29564422369003296, Accuracy: 29.543048858642578\n",
            "Epoch 693, Loss: 0.2955794930458069, Accuracy: 29.536787033081055\n",
            "Epoch 694, Loss: 0.29551634192466736, Accuracy: 29.530742645263672\n",
            "Epoch 695, Loss: 0.2954491972923279, Accuracy: 29.524415969848633\n",
            "Epoch 696, Loss: 0.29538437724113464, Accuracy: 29.518545150756836\n",
            "Epoch 697, Loss: 0.2953280508518219, Accuracy: 29.51262664794922\n",
            "Epoch 698, Loss: 0.295258492231369, Accuracy: 29.50643539428711\n",
            "Epoch 699, Loss: 0.29519394040107727, Accuracy: 29.500337600708008\n",
            "Epoch 700, Loss: 0.29512348771095276, Accuracy: 29.49408531188965\n",
            "Epoch 701, Loss: 0.295056015253067, Accuracy: 29.487916946411133\n",
            "Epoch 702, Loss: 0.2949845492839813, Accuracy: 29.481578826904297\n",
            "Epoch 703, Loss: 0.29491567611694336, Accuracy: 29.475419998168945\n",
            "Epoch 704, Loss: 0.2948501408100128, Accuracy: 29.46939468383789\n",
            "Epoch 705, Loss: 0.294784814119339, Accuracy: 29.463300704956055\n",
            "Epoch 706, Loss: 0.29474303126335144, Accuracy: 29.457447052001953\n",
            "Epoch 707, Loss: 0.2946811318397522, Accuracy: 29.451793670654297\n",
            "Epoch 708, Loss: 0.29461669921875, Accuracy: 29.445880889892578\n",
            "Epoch 709, Loss: 0.294568806886673, Accuracy: 29.439979553222656\n",
            "Epoch 710, Loss: 0.29450932145118713, Accuracy: 29.434192657470703\n",
            "Epoch 711, Loss: 0.29445675015449524, Accuracy: 29.428407669067383\n",
            "Epoch 712, Loss: 0.29439061880111694, Accuracy: 29.422388076782227\n",
            "Epoch 713, Loss: 0.2943279445171356, Accuracy: 29.416196823120117\n",
            "Epoch 714, Loss: 0.29426297545433044, Accuracy: 29.41029930114746\n",
            "Epoch 715, Loss: 0.2942037582397461, Accuracy: 29.404586791992188\n",
            "Epoch 716, Loss: 0.29414379596710205, Accuracy: 29.398710250854492\n",
            "Epoch 717, Loss: 0.2940821647644043, Accuracy: 29.392683029174805\n",
            "Epoch 718, Loss: 0.2940234839916229, Accuracy: 29.386646270751953\n",
            "Epoch 719, Loss: 0.29395708441734314, Accuracy: 29.380399703979492\n",
            "Epoch 720, Loss: 0.2939067780971527, Accuracy: 29.374393463134766\n",
            "Epoch 721, Loss: 0.2938574552536011, Accuracy: 29.368764877319336\n",
            "Epoch 722, Loss: 0.2937939465045929, Accuracy: 29.36314582824707\n",
            "Epoch 723, Loss: 0.2937472462654114, Accuracy: 29.357284545898438\n",
            "Epoch 724, Loss: 0.29369083046913147, Accuracy: 29.351356506347656\n",
            "Epoch 725, Loss: 0.2936301529407501, Accuracy: 29.345321655273438\n",
            "Epoch 726, Loss: 0.293567955493927, Accuracy: 29.339488983154297\n",
            "Epoch 727, Loss: 0.2935054302215576, Accuracy: 29.333955764770508\n",
            "Epoch 728, Loss: 0.2934497892856598, Accuracy: 29.328107833862305\n",
            "Epoch 729, Loss: 0.2933955490589142, Accuracy: 29.322254180908203\n",
            "Epoch 730, Loss: 0.2933328151702881, Accuracy: 29.316556930541992\n",
            "Epoch 731, Loss: 0.2932729721069336, Accuracy: 29.31060218811035\n",
            "Epoch 732, Loss: 0.29323476552963257, Accuracy: 29.304786682128906\n",
            "Epoch 733, Loss: 0.2931689918041229, Accuracy: 29.298921585083008\n",
            "Epoch 734, Loss: 0.29310542345046997, Accuracy: 29.293167114257812\n",
            "Epoch 735, Loss: 0.2930567264556885, Accuracy: 29.287321090698242\n",
            "Epoch 736, Loss: 0.2930084466934204, Accuracy: 29.28152084350586\n",
            "Epoch 737, Loss: 0.2929452061653137, Accuracy: 29.275697708129883\n",
            "Epoch 738, Loss: 0.29288238286972046, Accuracy: 29.26986312866211\n",
            "Epoch 739, Loss: 0.29282283782958984, Accuracy: 29.264217376708984\n",
            "Epoch 740, Loss: 0.2927660048007965, Accuracy: 29.25843048095703\n",
            "Epoch 741, Loss: 0.29270732402801514, Accuracy: 29.25284767150879\n",
            "Epoch 742, Loss: 0.2926521897315979, Accuracy: 29.24732780456543\n",
            "Epoch 743, Loss: 0.2925909459590912, Accuracy: 29.24179458618164\n",
            "Epoch 744, Loss: 0.2925254702568054, Accuracy: 29.235931396484375\n",
            "Epoch 745, Loss: 0.29247599840164185, Accuracy: 29.230270385742188\n",
            "Epoch 746, Loss: 0.29242807626724243, Accuracy: 29.22498321533203\n",
            "Epoch 747, Loss: 0.2923707664012909, Accuracy: 29.21937370300293\n",
            "Epoch 748, Loss: 0.2923148274421692, Accuracy: 29.2137451171875\n",
            "Epoch 749, Loss: 0.29225531220436096, Accuracy: 29.208431243896484\n",
            "Epoch 750, Loss: 0.2921977639198303, Accuracy: 29.20294189453125\n",
            "Epoch 751, Loss: 0.29214340448379517, Accuracy: 29.19750213623047\n",
            "Epoch 752, Loss: 0.2920876741409302, Accuracy: 29.191783905029297\n",
            "Epoch 753, Loss: 0.29203057289123535, Accuracy: 29.18626594543457\n",
            "Epoch 754, Loss: 0.2919781804084778, Accuracy: 29.180891036987305\n",
            "Epoch 755, Loss: 0.29192054271698, Accuracy: 29.17540740966797\n",
            "Epoch 756, Loss: 0.2918640077114105, Accuracy: 29.170421600341797\n",
            "Epoch 757, Loss: 0.2918083071708679, Accuracy: 29.16519546508789\n",
            "Epoch 758, Loss: 0.29176488518714905, Accuracy: 29.160324096679688\n",
            "Epoch 759, Loss: 0.2917097210884094, Accuracy: 29.154983520507812\n",
            "Epoch 760, Loss: 0.2916519045829773, Accuracy: 29.14984130859375\n",
            "Epoch 761, Loss: 0.29159027338027954, Accuracy: 29.144433975219727\n",
            "Epoch 762, Loss: 0.29153844714164734, Accuracy: 29.13885498046875\n",
            "Epoch 763, Loss: 0.29149776697158813, Accuracy: 29.133447647094727\n",
            "Epoch 764, Loss: 0.29144880175590515, Accuracy: 29.128360748291016\n",
            "Epoch 765, Loss: 0.29139381647109985, Accuracy: 29.123323440551758\n",
            "Epoch 766, Loss: 0.29133856296539307, Accuracy: 29.11804962158203\n",
            "Epoch 767, Loss: 0.2912833094596863, Accuracy: 29.112689971923828\n",
            "Epoch 768, Loss: 0.29123231768608093, Accuracy: 29.107412338256836\n",
            "Epoch 769, Loss: 0.29118186235427856, Accuracy: 29.10240936279297\n",
            "Epoch 770, Loss: 0.29113587737083435, Accuracy: 29.097261428833008\n",
            "Epoch 771, Loss: 0.2910892963409424, Accuracy: 29.092130661010742\n",
            "Epoch 772, Loss: 0.291042298078537, Accuracy: 29.086729049682617\n",
            "Epoch 773, Loss: 0.2910051643848419, Accuracy: 29.081783294677734\n",
            "Epoch 774, Loss: 0.29095083475112915, Accuracy: 29.076936721801758\n",
            "Epoch 775, Loss: 0.29089197516441345, Accuracy: 29.0716552734375\n",
            "Epoch 776, Loss: 0.2908426523208618, Accuracy: 29.06641387939453\n",
            "Epoch 777, Loss: 0.2907983958721161, Accuracy: 29.061382293701172\n",
            "Epoch 778, Loss: 0.29074791073799133, Accuracy: 29.056549072265625\n",
            "Epoch 779, Loss: 0.2907111942768097, Accuracy: 29.051416397094727\n",
            "Epoch 780, Loss: 0.29065683484077454, Accuracy: 29.046388626098633\n",
            "Epoch 781, Loss: 0.29059872031211853, Accuracy: 29.041296005249023\n",
            "Epoch 782, Loss: 0.2905512750148773, Accuracy: 29.03618812561035\n",
            "Epoch 783, Loss: 0.29050031304359436, Accuracy: 29.031145095825195\n",
            "Epoch 784, Loss: 0.29045990109443665, Accuracy: 29.0261173248291\n",
            "Epoch 785, Loss: 0.29039961099624634, Accuracy: 29.020694732666016\n",
            "Epoch 786, Loss: 0.29034656286239624, Accuracy: 29.015666961669922\n",
            "Epoch 787, Loss: 0.2903047204017639, Accuracy: 29.011035919189453\n",
            "Epoch 788, Loss: 0.29024818539619446, Accuracy: 29.005998611450195\n",
            "Epoch 789, Loss: 0.29019251465797424, Accuracy: 29.000961303710938\n",
            "Epoch 790, Loss: 0.29015007615089417, Accuracy: 28.995864868164062\n",
            "Epoch 791, Loss: 0.2900948226451874, Accuracy: 28.99104118347168\n",
            "Epoch 792, Loss: 0.290038138628006, Accuracy: 28.985851287841797\n",
            "Epoch 793, Loss: 0.28998520970344543, Accuracy: 28.98092269897461\n",
            "Epoch 794, Loss: 0.2899322807788849, Accuracy: 28.97600746154785\n",
            "Epoch 795, Loss: 0.2898761034011841, Accuracy: 28.970834732055664\n",
            "Epoch 796, Loss: 0.2898204028606415, Accuracy: 28.965791702270508\n",
            "Epoch 797, Loss: 0.2897670567035675, Accuracy: 28.960996627807617\n",
            "Epoch 798, Loss: 0.2897154986858368, Accuracy: 28.95583724975586\n",
            "Epoch 799, Loss: 0.28966575860977173, Accuracy: 28.95087242126465\n",
            "Epoch 800, Loss: 0.289617657661438, Accuracy: 28.945878982543945\n",
            "Epoch 801, Loss: 0.28956061601638794, Accuracy: 28.940872192382812\n",
            "Epoch 802, Loss: 0.2895062267780304, Accuracy: 28.93575096130371\n",
            "Epoch 803, Loss: 0.28946739435195923, Accuracy: 28.931001663208008\n",
            "Epoch 804, Loss: 0.2894386649131775, Accuracy: 28.926715850830078\n",
            "Epoch 805, Loss: 0.2893824279308319, Accuracy: 28.921627044677734\n",
            "Epoch 806, Loss: 0.28933876752853394, Accuracy: 28.916629791259766\n",
            "Epoch 807, Loss: 0.28929442167282104, Accuracy: 28.911907196044922\n",
            "Epoch 808, Loss: 0.28925368189811707, Accuracy: 28.907028198242188\n",
            "Epoch 809, Loss: 0.2892049551010132, Accuracy: 28.90209197998047\n",
            "Epoch 810, Loss: 0.2891550064086914, Accuracy: 28.897371292114258\n",
            "Epoch 811, Loss: 0.2891082465648651, Accuracy: 28.89261817932129\n",
            "Epoch 812, Loss: 0.2890532612800598, Accuracy: 28.887712478637695\n",
            "Epoch 813, Loss: 0.2889992892742157, Accuracy: 28.883024215698242\n",
            "Epoch 814, Loss: 0.2889508605003357, Accuracy: 28.8781795501709\n",
            "Epoch 815, Loss: 0.2888965308666229, Accuracy: 28.87345314025879\n",
            "Epoch 816, Loss: 0.2888471782207489, Accuracy: 28.86880111694336\n",
            "Epoch 817, Loss: 0.28880029916763306, Accuracy: 28.86435317993164\n",
            "Epoch 818, Loss: 0.28875383734703064, Accuracy: 28.859779357910156\n",
            "Epoch 819, Loss: 0.28870701789855957, Accuracy: 28.85505485534668\n",
            "Epoch 820, Loss: 0.2886618971824646, Accuracy: 28.85015869140625\n",
            "Epoch 821, Loss: 0.2886304557323456, Accuracy: 28.845640182495117\n",
            "Epoch 822, Loss: 0.288583904504776, Accuracy: 28.840961456298828\n",
            "Epoch 823, Loss: 0.28853681683540344, Accuracy: 28.836437225341797\n",
            "Epoch 824, Loss: 0.2884884178638458, Accuracy: 28.831708908081055\n",
            "Epoch 825, Loss: 0.28844135999679565, Accuracy: 28.826961517333984\n",
            "Epoch 826, Loss: 0.28839045763015747, Accuracy: 28.822481155395508\n",
            "Epoch 827, Loss: 0.28834131360054016, Accuracy: 28.81768035888672\n",
            "Epoch 828, Loss: 0.288295179605484, Accuracy: 28.813138961791992\n",
            "Epoch 829, Loss: 0.28824442625045776, Accuracy: 28.808767318725586\n",
            "Epoch 830, Loss: 0.28820136189460754, Accuracy: 28.804248809814453\n",
            "Epoch 831, Loss: 0.2881627082824707, Accuracy: 28.799718856811523\n",
            "Epoch 832, Loss: 0.28812628984451294, Accuracy: 28.79534912109375\n",
            "Epoch 833, Loss: 0.28808072209358215, Accuracy: 28.79087257385254\n",
            "Epoch 834, Loss: 0.28803446888923645, Accuracy: 28.786340713500977\n",
            "Epoch 835, Loss: 0.2879926264286041, Accuracy: 28.781795501708984\n",
            "Epoch 836, Loss: 0.28794899582862854, Accuracy: 28.777402877807617\n",
            "Epoch 837, Loss: 0.28790542483329773, Accuracy: 28.773027420043945\n",
            "Epoch 838, Loss: 0.28787219524383545, Accuracy: 28.76837921142578\n",
            "Epoch 839, Loss: 0.2878214120864868, Accuracy: 28.763824462890625\n",
            "Epoch 840, Loss: 0.28777551651000977, Accuracy: 28.75923728942871\n",
            "Epoch 841, Loss: 0.2877365052700043, Accuracy: 28.755149841308594\n",
            "Epoch 842, Loss: 0.2877000570297241, Accuracy: 28.750913619995117\n",
            "Epoch 843, Loss: 0.28765588998794556, Accuracy: 28.746562957763672\n",
            "Epoch 844, Loss: 0.2876183092594147, Accuracy: 28.742197036743164\n",
            "Epoch 845, Loss: 0.28756552934646606, Accuracy: 28.73759651184082\n",
            "Epoch 846, Loss: 0.28752022981643677, Accuracy: 28.7330265045166\n",
            "Epoch 847, Loss: 0.28748035430908203, Accuracy: 28.72854232788086\n",
            "Epoch 848, Loss: 0.2874315679073334, Accuracy: 28.72380828857422\n",
            "Epoch 849, Loss: 0.28738540410995483, Accuracy: 28.719154357910156\n",
            "Epoch 850, Loss: 0.2873364984989166, Accuracy: 28.71459197998047\n",
            "Epoch 851, Loss: 0.28728601336479187, Accuracy: 28.710052490234375\n",
            "Epoch 852, Loss: 0.2872422933578491, Accuracy: 28.705575942993164\n",
            "Epoch 853, Loss: 0.2872094213962555, Accuracy: 28.701156616210938\n",
            "Epoch 854, Loss: 0.28716298937797546, Accuracy: 28.696664810180664\n",
            "Epoch 855, Loss: 0.28711166977882385, Accuracy: 28.69211196899414\n",
            "Epoch 856, Loss: 0.28706803917884827, Accuracy: 28.687747955322266\n",
            "Epoch 857, Loss: 0.28701937198638916, Accuracy: 28.683338165283203\n",
            "Epoch 858, Loss: 0.2869735062122345, Accuracy: 28.679224014282227\n",
            "Epoch 859, Loss: 0.2869263291358948, Accuracy: 28.674850463867188\n",
            "Epoch 860, Loss: 0.28688088059425354, Accuracy: 28.670522689819336\n",
            "Epoch 861, Loss: 0.2868387699127197, Accuracy: 28.66615104675293\n",
            "Epoch 862, Loss: 0.2867881655693054, Accuracy: 28.661691665649414\n",
            "Epoch 863, Loss: 0.2867473363876343, Accuracy: 28.65730857849121\n",
            "Epoch 864, Loss: 0.286697655916214, Accuracy: 28.652915954589844\n",
            "Epoch 865, Loss: 0.2866649031639099, Accuracy: 28.648746490478516\n",
            "Epoch 866, Loss: 0.2866268455982208, Accuracy: 28.6445255279541\n",
            "Epoch 867, Loss: 0.28657856583595276, Accuracy: 28.64017105102539\n",
            "Epoch 868, Loss: 0.28655368089675903, Accuracy: 28.63580894470215\n",
            "Epoch 869, Loss: 0.28650757670402527, Accuracy: 28.63154411315918\n",
            "Epoch 870, Loss: 0.2864633798599243, Accuracy: 28.627288818359375\n",
            "Epoch 871, Loss: 0.28643083572387695, Accuracy: 28.622976303100586\n",
            "Epoch 872, Loss: 0.2863941788673401, Accuracy: 28.618684768676758\n",
            "Epoch 873, Loss: 0.2863636910915375, Accuracy: 28.614543914794922\n",
            "Epoch 874, Loss: 0.2863205671310425, Accuracy: 28.610530853271484\n",
            "Epoch 875, Loss: 0.28627562522888184, Accuracy: 28.606233596801758\n",
            "Epoch 876, Loss: 0.28622663021087646, Accuracy: 28.60198974609375\n",
            "Epoch 877, Loss: 0.2861809730529785, Accuracy: 28.597522735595703\n",
            "Epoch 878, Loss: 0.2861350476741791, Accuracy: 28.593313217163086\n",
            "Epoch 879, Loss: 0.28609317541122437, Accuracy: 28.589248657226562\n",
            "Epoch 880, Loss: 0.28604355454444885, Accuracy: 28.584814071655273\n",
            "Epoch 881, Loss: 0.2859968841075897, Accuracy: 28.580686569213867\n",
            "Epoch 882, Loss: 0.28595170378685, Accuracy: 28.576457977294922\n",
            "Epoch 883, Loss: 0.28591784834861755, Accuracy: 28.572113037109375\n",
            "Epoch 884, Loss: 0.2858748137950897, Accuracy: 28.56789207458496\n",
            "Epoch 885, Loss: 0.285830557346344, Accuracy: 28.563642501831055\n",
            "Epoch 886, Loss: 0.28578487038612366, Accuracy: 28.559457778930664\n",
            "Epoch 887, Loss: 0.28573811054229736, Accuracy: 28.555330276489258\n",
            "Epoch 888, Loss: 0.2856903672218323, Accuracy: 28.551176071166992\n",
            "Epoch 889, Loss: 0.28565022349357605, Accuracy: 28.547016143798828\n",
            "Epoch 890, Loss: 0.28560394048690796, Accuracy: 28.54291534423828\n",
            "Epoch 891, Loss: 0.2855716943740845, Accuracy: 28.538755416870117\n",
            "Epoch 892, Loss: 0.2855279743671417, Accuracy: 28.53464698791504\n",
            "Epoch 893, Loss: 0.285482794046402, Accuracy: 28.5306339263916\n",
            "Epoch 894, Loss: 0.2854475975036621, Accuracy: 28.52642822265625\n",
            "Epoch 895, Loss: 0.2853985130786896, Accuracy: 28.522098541259766\n",
            "Epoch 896, Loss: 0.285359263420105, Accuracy: 28.5179443359375\n",
            "Epoch 897, Loss: 0.28533148765563965, Accuracy: 28.514135360717773\n",
            "Epoch 898, Loss: 0.2852858901023865, Accuracy: 28.510046005249023\n",
            "Epoch 899, Loss: 0.28524649143218994, Accuracy: 28.505924224853516\n",
            "Epoch 900, Loss: 0.2852042317390442, Accuracy: 28.502120971679688\n",
            "Epoch 901, Loss: 0.285160630941391, Accuracy: 28.498046875\n",
            "Epoch 902, Loss: 0.28511714935302734, Accuracy: 28.49384880065918\n",
            "Epoch 903, Loss: 0.2850787341594696, Accuracy: 28.489816665649414\n",
            "Epoch 904, Loss: 0.28503745794296265, Accuracy: 28.485769271850586\n",
            "Epoch 905, Loss: 0.28499364852905273, Accuracy: 28.481748580932617\n",
            "Epoch 906, Loss: 0.284970760345459, Accuracy: 28.47762680053711\n",
            "Epoch 907, Loss: 0.28492653369903564, Accuracy: 28.473695755004883\n",
            "Epoch 908, Loss: 0.28487998247146606, Accuracy: 28.46962547302246\n",
            "Epoch 909, Loss: 0.2848336100578308, Accuracy: 28.465431213378906\n",
            "Epoch 910, Loss: 0.28478944301605225, Accuracy: 28.461441040039062\n",
            "Epoch 911, Loss: 0.28475168347358704, Accuracy: 28.457651138305664\n",
            "Epoch 912, Loss: 0.2847093939781189, Accuracy: 28.453710556030273\n",
            "Epoch 913, Loss: 0.28466367721557617, Accuracy: 28.449607849121094\n",
            "Epoch 914, Loss: 0.2846216857433319, Accuracy: 28.445714950561523\n",
            "Epoch 915, Loss: 0.2845853865146637, Accuracy: 28.441843032836914\n",
            "Epoch 916, Loss: 0.2845400273799896, Accuracy: 28.43778419494629\n",
            "Epoch 917, Loss: 0.28450700640678406, Accuracy: 28.43390464782715\n",
            "Epoch 918, Loss: 0.28446531295776367, Accuracy: 28.430042266845703\n",
            "Epoch 919, Loss: 0.28441908955574036, Accuracy: 28.426054000854492\n",
            "Epoch 920, Loss: 0.2843802869319916, Accuracy: 28.422121047973633\n",
            "Epoch 921, Loss: 0.2843399941921234, Accuracy: 28.418264389038086\n",
            "Epoch 922, Loss: 0.2842988073825836, Accuracy: 28.41425895690918\n",
            "Epoch 923, Loss: 0.28425467014312744, Accuracy: 28.41028594970703\n",
            "Epoch 924, Loss: 0.2842105031013489, Accuracy: 28.406408309936523\n",
            "Epoch 925, Loss: 0.28417322039604187, Accuracy: 28.402557373046875\n",
            "Epoch 926, Loss: 0.28413861989974976, Accuracy: 28.39852523803711\n",
            "Epoch 927, Loss: 0.28410324454307556, Accuracy: 28.39456558227539\n",
            "Epoch 928, Loss: 0.2840677797794342, Accuracy: 28.39060401916504\n",
            "Epoch 929, Loss: 0.28402194380760193, Accuracy: 28.38652801513672\n",
            "Epoch 930, Loss: 0.28398430347442627, Accuracy: 28.382583618164062\n",
            "Epoch 931, Loss: 0.28394055366516113, Accuracy: 28.378530502319336\n",
            "Epoch 932, Loss: 0.2839108109474182, Accuracy: 28.374818801879883\n",
            "Epoch 933, Loss: 0.28387272357940674, Accuracy: 28.37105369567871\n",
            "Epoch 934, Loss: 0.28384116291999817, Accuracy: 28.367280960083008\n",
            "Epoch 935, Loss: 0.28379637002944946, Accuracy: 28.363353729248047\n",
            "Epoch 936, Loss: 0.2837508022785187, Accuracy: 28.359403610229492\n",
            "Epoch 937, Loss: 0.2837100028991699, Accuracy: 28.355682373046875\n",
            "Epoch 938, Loss: 0.2836701571941376, Accuracy: 28.351959228515625\n",
            "Epoch 939, Loss: 0.2836335003376007, Accuracy: 28.348133087158203\n",
            "Epoch 940, Loss: 0.2835959494113922, Accuracy: 28.344282150268555\n",
            "Epoch 941, Loss: 0.2835526466369629, Accuracy: 28.340551376342773\n",
            "Epoch 942, Loss: 0.2835090160369873, Accuracy: 28.33668327331543\n",
            "Epoch 943, Loss: 0.28346702456474304, Accuracy: 28.333080291748047\n",
            "Epoch 944, Loss: 0.2834247052669525, Accuracy: 28.32929801940918\n",
            "Epoch 945, Loss: 0.2833855152130127, Accuracy: 28.325536727905273\n",
            "Epoch 946, Loss: 0.28334543108940125, Accuracy: 28.32185935974121\n",
            "Epoch 947, Loss: 0.28330498933792114, Accuracy: 28.318082809448242\n",
            "Epoch 948, Loss: 0.28326404094696045, Accuracy: 28.314498901367188\n",
            "Epoch 949, Loss: 0.28322112560272217, Accuracy: 28.31079864501953\n",
            "Epoch 950, Loss: 0.2831800580024719, Accuracy: 28.30709457397461\n",
            "Epoch 951, Loss: 0.28313738107681274, Accuracy: 28.303285598754883\n",
            "Epoch 952, Loss: 0.28309816122055054, Accuracy: 28.299575805664062\n",
            "Epoch 953, Loss: 0.2830663025379181, Accuracy: 28.29597282409668\n",
            "Epoch 954, Loss: 0.28302305936813354, Accuracy: 28.292179107666016\n",
            "Epoch 955, Loss: 0.28298595547676086, Accuracy: 28.28850746154785\n",
            "Epoch 956, Loss: 0.28295037150382996, Accuracy: 28.284942626953125\n",
            "Epoch 957, Loss: 0.2829228937625885, Accuracy: 28.28163719177246\n",
            "Epoch 958, Loss: 0.2828887104988098, Accuracy: 28.277978897094727\n",
            "Epoch 959, Loss: 0.2828478217124939, Accuracy: 28.2744083404541\n",
            "Epoch 960, Loss: 0.28281673789024353, Accuracy: 28.27070426940918\n",
            "Epoch 961, Loss: 0.2827792465686798, Accuracy: 28.267282485961914\n",
            "Epoch 962, Loss: 0.28274181485176086, Accuracy: 28.263545989990234\n",
            "Epoch 963, Loss: 0.2827017903327942, Accuracy: 28.259849548339844\n",
            "Epoch 964, Loss: 0.2826610505580902, Accuracy: 28.256135940551758\n",
            "Epoch 965, Loss: 0.28263059258461, Accuracy: 28.25259017944336\n",
            "Epoch 966, Loss: 0.2826023995876312, Accuracy: 28.248977661132812\n",
            "Epoch 967, Loss: 0.28256016969680786, Accuracy: 28.24527931213379\n",
            "Epoch 968, Loss: 0.2825220227241516, Accuracy: 28.24165153503418\n",
            "Epoch 969, Loss: 0.2824845612049103, Accuracy: 28.237802505493164\n",
            "Epoch 970, Loss: 0.2824581265449524, Accuracy: 28.23413848876953\n",
            "Epoch 971, Loss: 0.2824191153049469, Accuracy: 28.230783462524414\n",
            "Epoch 972, Loss: 0.2823844850063324, Accuracy: 28.22718048095703\n",
            "Epoch 973, Loss: 0.2823421359062195, Accuracy: 28.223445892333984\n",
            "Epoch 974, Loss: 0.28230977058410645, Accuracy: 28.21974754333496\n",
            "Epoch 975, Loss: 0.2822721004486084, Accuracy: 28.216007232666016\n",
            "Epoch 976, Loss: 0.2822514474391937, Accuracy: 28.212451934814453\n",
            "Epoch 977, Loss: 0.28221651911735535, Accuracy: 28.208702087402344\n",
            "Epoch 978, Loss: 0.28218647837638855, Accuracy: 28.20526695251465\n",
            "Epoch 979, Loss: 0.28215521574020386, Accuracy: 28.20163917541504\n",
            "Epoch 980, Loss: 0.28211575746536255, Accuracy: 28.197940826416016\n",
            "Epoch 981, Loss: 0.28207486867904663, Accuracy: 28.194326400756836\n",
            "Epoch 982, Loss: 0.2820356488227844, Accuracy: 28.19066047668457\n",
            "Epoch 983, Loss: 0.28200116753578186, Accuracy: 28.187036514282227\n",
            "Epoch 984, Loss: 0.281972199678421, Accuracy: 28.183635711669922\n",
            "Epoch 985, Loss: 0.2819332778453827, Accuracy: 28.180206298828125\n",
            "Epoch 986, Loss: 0.28189972043037415, Accuracy: 28.176788330078125\n",
            "Epoch 987, Loss: 0.2818734049797058, Accuracy: 28.173309326171875\n",
            "Epoch 988, Loss: 0.2818351089954376, Accuracy: 28.16974449157715\n",
            "Epoch 989, Loss: 0.2818056344985962, Accuracy: 28.166194915771484\n",
            "Epoch 990, Loss: 0.28176936507225037, Accuracy: 28.16290855407715\n",
            "Epoch 991, Loss: 0.2817334532737732, Accuracy: 28.15948486328125\n",
            "Epoch 992, Loss: 0.2816981077194214, Accuracy: 28.156312942504883\n",
            "Epoch 993, Loss: 0.2816665470600128, Accuracy: 28.15290069580078\n",
            "Epoch 994, Loss: 0.28162866830825806, Accuracy: 28.149450302124023\n",
            "Epoch 995, Loss: 0.28159046173095703, Accuracy: 28.14592933654785\n",
            "Epoch 996, Loss: 0.2815548777580261, Accuracy: 28.142436981201172\n",
            "Epoch 997, Loss: 0.28152427077293396, Accuracy: 28.13909149169922\n",
            "Epoch 998, Loss: 0.28148722648620605, Accuracy: 28.135475158691406\n",
            "Epoch 999, Loss: 0.2814522981643677, Accuracy: 28.13205337524414\n",
            "Epoch 1000, Loss: 0.28141137957572937, Accuracy: 28.12853240966797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋 및 학습 파라미터 저장\n",
        "np.savez_compressed('ch2_dataset.npz',inputs=pts,labels=labels) #압축하여 저장\n",
        "\n",
        "w_h,b_h = medel.d1.get_weights() #히든레이어에 weight와 bias\n",
        "w_o,b_o = medel.d2.get_weights() #아웃풋레이어에 weight와 bias\n",
        "w_h = np.transpose(w_h)\n",
        "w_o = np.transpose(w_o)\n",
        "np.savez_compressed('ch2_dataset.npz',\n",
        "                    w_h=w_h,\n",
        "                    b_h=b_h,\n",
        "                    w_o=w_o,\n",
        "                    b_o=b_o)"
      ],
      "metadata": {
        "id": "DC28DK89FVNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "수치 미분을 이용한 심층 신경망 학습"
      ],
      "metadata": {
        "id": "WN85WZHKO7-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Lrrh5PRmFVOf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#유틸리티 함수\n",
        "epsilon = 0.0001\n",
        "\n",
        "def _t(x):\n",
        "  return np.transpose(x)\n",
        "\n",
        "def _m(A,B):\n",
        "  return np.matmul(A,B)\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1+np.exp(-x))\n",
        "\n",
        "def mean_squared_error(h,y):\n",
        "  return 1/2*np.mean(np.square(h-y))"
      ],
      "metadata": {
        "id": "kfVQvLukFVPc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#뉴련구현\n",
        "class Neuron:\n",
        "  def __init__(self,W,b,a):\n",
        "    #Model Parameter\n",
        "    self.W = W\n",
        "    self.b = b\n",
        "    self.a = a\n",
        "\n",
        "    #Gradients\n",
        "    self.dw = np.zeros_like(self.W)\n",
        "    self.db = np.zeros_like(self.b)\n",
        "\n",
        "  def __call__(self,x):\n",
        "    return self.a(_m(_t(self.W),x)+self.b) #activation((W^T)x+b)\n",
        "    #~~"
      ],
      "metadata": {
        "id": "F4AkEf7RFVS9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "역전파 학습법을 이용한 심층 신경망 학습"
      ],
      "metadata": {
        "id": "9YV0TF0hbnXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "w-UqnX1zbq31"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#유틸리티 함수\n",
        "epsilon = 0.0001\n",
        "\n",
        "def _t(x):\n",
        "  return np.transpose(x)\n",
        "\n",
        "def _m(A,B):\n",
        "  return np.matmul(A,B)"
      ],
      "metadata": {
        "id": "iihj_tTsbmW9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sigmoid 구현\n",
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    self.last_o = 1\n",
        "\n",
        "  def __call__(self,x):\n",
        "    self.last_o = 1/(1.0 + np.exp(-x))\n",
        "    return self.last_o\n",
        "\n",
        "  def grad(self): #sigmoid(x)(1-sigmoid(x))\n",
        "    return self.last_o *(1-self.last_o)"
      ],
      "metadata": {
        "id": "x1nwzwyXbmZa"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean Squared Error 구현\n",
        "class MeanSquaredError:\n",
        "  def __init__(self):\n",
        "    #gradient\n",
        "    self.dh = 1\n",
        "    self.last_diff = 1\n",
        "\n",
        "  def __call__(self,h,y): #1/2 *mean((h-y)^2)\n",
        "    self.last_diff = h-y\n",
        "    return 1/2 * np.mean(np.square(h-y))\n",
        "\n",
        "  def grad(self): #h-y\n",
        "    return self.last_diff\n"
      ],
      "metadata": {
        "id": "r42cppcdda7U"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#뉴련 구현(fully-connected layer 구현)\n",
        "class Neuron:\n",
        "  def __init__(self,W,b,a_obj):\n",
        "    #Model parameters\n",
        "    self.W = W\n",
        "    self.b = b\n",
        "    self.a = a_obj()\n",
        "\n",
        "    #gradient\n",
        "    self.dW = np.zeros_like(self.W)\n",
        "    self.db = np.zeros_like(self.b)\n",
        "    self.dh = np.zeros_like(_t(self.W))\n",
        "\n",
        "    self.last_x = np.zeros((self.W.shape[0])) #W grad를 위해서 마지막 x저장\n",
        "    self.last_h = np.zeros((self.W.shape[1]))\n",
        "\n",
        "  def __call__(self,x):\n",
        "    self.last_x = x\n",
        "    self.last_h = _m(_t(self.W),x) + self.b\n",
        "    return self.a(self.last_h)\n",
        "\n",
        "  def grad(self): #dy/dh = W\n",
        "    return self.W * self.a.grad()\n",
        "\n",
        "  def grad_W(self,dh):\n",
        "    grad = np.ones_like(self.W)\n",
        "    grad_a = self.a.grad()\n",
        "    for j in range(grad.shape[1]): #dy/dw = x\n",
        "      grad[:,j] = dh[j] *grad_a[j] * self.last_x\n",
        "    return grad\n",
        "\n",
        "  def grad_b(self,dh): #dy/dh = 1\n",
        "    return dh*self.a.grad()"
      ],
      "metadata": {
        "id": "zKX4EHKvbmb8"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#심층신경망 구현\n",
        "class DNN:\n",
        "  def __init__(self,hidden_depth,num_neuron,input,output,activation=Sigmoid):\n",
        "    def init_var(i,o):\n",
        "      return np.random.normal(0.0,0.01,(i,o)),np.zeros((o,))\n",
        "\n",
        "    self.sequence = list()\n",
        "    #First hidden layer\n",
        "    W,b = init_var(input,num_neuron)\n",
        "    self.sequence.append(Neuron(W,b,activation))\n",
        "\n",
        "    #Hidden Layers\n",
        "    for index in range(hidden_depth):\n",
        "      W,b = init_var(num_neuron,num_neuron)\n",
        "      self.sequence.append(Neuron(W,b,activation))\n",
        "\n",
        "    #Output layer\n",
        "    W,b = init_var(num_neuron,output)\n",
        "    self.sequence.append(Neuron(W,b,activation))\n",
        "\n",
        "  def __call__(self,x):\n",
        "    for layer in self.sequence:\n",
        "      x = layer(x)\n",
        "    return x\n",
        "\n",
        "  def calc_gradient(self,loss_obj):\n",
        "    loss_obj.dh = loss_obj.grad()\n",
        "    self.sequence.append(loss_obj)\n",
        "    #back-prop loop\n",
        "    for i in range(len(self.sequence)-1,0,-1):\n",
        "        l1 = self.sequence[i]\n",
        "        l0= self.sequence[i-1]\n",
        "\n",
        "\n",
        "        l0.dh = _m(l0.grad(),l1.dh)\n",
        "        l0.dW = l0.grad_W(l1.dh)\n",
        "        l0.db = l0.grad_b(l1.dh)\n",
        "\n",
        "    self.sequence.remove(loss_obj)"
      ],
      "metadata": {
        "id": "C2E_YYh9bmel"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#경사하강 학습법\n",
        "def gradient_descent(network,x,y,loss_obj,alpha=0.01):\n",
        "  loss = loss_obj(network(x),y) #Forward inference\n",
        "  network.calc_gradient(loss_obj) #Back-propagation\n",
        "  for layer in network.sequence:\n",
        "    layer.W += -alpha * layer.dW\n",
        "    layer.b += -alpha * layer.db\n",
        "  return loss"
      ],
      "metadata": {
        "id": "05UNW9NmbmhV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#동작테스트\n",
        "x = np.random.normal(0.0,1.0,(10,))\n",
        "y = np.random.normal(0.0,1.0,(2,))\n",
        "\n",
        "t = time.time()\n",
        "dnn = DNN(hidden_depth=5,num_neuron=32,input=10,output=2,activation=Sigmoid)\n",
        "loss_obj = MeanSquaredError()\n",
        "for epoch in range(100):\n",
        "  loss = gradient_descent(dnn,x,y,loss_obj,alpha=0.01)\n",
        "  print(\"Epoch {}: Test loss {}\".format(epoch,loss))\n",
        "print('{} seconds elapsed.'.format(time.time()-t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOFT4QfactqK",
        "outputId": "de60992d-4751-4bf3-dd0b-a0d279fa1390"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Test loss 0.36131266164945375\n",
            "Epoch 1: Test loss 0.357288056485878\n",
            "Epoch 2: Test loss 0.35330858289968736\n",
            "Epoch 3: Test loss 0.3493755003403499\n",
            "Epoch 4: Test loss 0.3454899609569206\n",
            "Epoch 5: Test loss 0.341653009699399\n",
            "Epoch 6: Test loss 0.3378655849874046\n",
            "Epoch 7: Test loss 0.33412851990994746\n",
            "Epoch 8: Test loss 0.33044254391656663\n",
            "Epoch 9: Test loss 0.32680828495743447\n",
            "Epoch 10: Test loss 0.3232262720281667\n",
            "Epoch 11: Test loss 0.31969693807400124\n",
            "Epoch 12: Test loss 0.3162206232076507\n",
            "Epoch 13: Test loss 0.312797578195447\n",
            "Epoch 14: Test loss 0.30942796816728924\n",
            "Epoch 15: Test loss 0.30611187650732896\n",
            "Epoch 16: Test loss 0.30284930888417705\n",
            "Epoch 17: Test loss 0.299640197381633\n",
            "Epoch 18: Test loss 0.2964844046934355\n",
            "Epoch 19: Test loss 0.29338172834824483\n",
            "Epoch 20: Test loss 0.290331904933918\n",
            "Epoch 21: Test loss 0.28733461429307616\n",
            "Epoch 22: Test loss 0.2843894836649205\n",
            "Epoch 23: Test loss 0.2814960917511931\n",
            "Epoch 24: Test loss 0.2786539726870468\n",
            "Epoch 25: Test loss 0.27586261990036465\n",
            "Epoch 26: Test loss 0.27312148984571105\n",
            "Epoch 27: Test loss 0.270430005601587\n",
            "Epoch 28: Test loss 0.2677875603219948\n",
            "Epoch 29: Test loss 0.26519352053546236\n",
            "Epoch 30: Test loss 0.2626472292866437\n",
            "Epoch 31: Test loss 0.2601480091173944\n",
            "Epoch 32: Test loss 0.25769516488581407\n",
            "Epoch 33: Test loss 0.2552879864231629\n",
            "Epoch 34: Test loss 0.2529257510298004\n",
            "Epoch 35: Test loss 0.25060772581236834\n",
            "Epoch 36: Test loss 0.24833316986535808\n",
            "Epoch 37: Test loss 0.24610133630097478\n",
            "Epoch 38: Test loss 0.2439114741318477\n",
            "Epoch 39: Test loss 0.24176283001164994\n",
            "Epoch 40: Test loss 0.23965464983909232\n",
            "Epoch 41: Test loss 0.23758618023105843\n",
            "Epoch 42: Test loss 0.23555666987085683\n",
            "Epoch 43: Test loss 0.23356537073770126\n",
            "Epoch 44: Test loss 0.23161153922359037\n",
            "Epoch 45: Test loss 0.22969443714376203\n",
            "Epoch 46: Test loss 0.2278133326468472\n",
            "Epoch 47: Test loss 0.22596750103075902\n",
            "Epoch 48: Test loss 0.2241562254702197\n",
            "Epoch 49: Test loss 0.22237879766167373\n",
            "Epoch 50: Test loss 0.22063451839115025\n",
            "Epoch 51: Test loss 0.2189226980304397\n",
            "Epoch 52: Test loss 0.21724265696673137\n",
            "Epoch 53: Test loss 0.2155937259706374\n",
            "Epoch 54: Test loss 0.21397524650729446\n",
            "Epoch 55: Test loss 0.2123865709950014\n",
            "Epoch 56: Test loss 0.21082706301561532\n",
            "Epoch 57: Test loss 0.20929609748069433\n",
            "Epoch 58: Test loss 0.20779306075714404\n",
            "Epoch 59: Test loss 0.2063173507559\n",
            "Epoch 60: Test loss 0.20486837698695778\n",
            "Epoch 61: Test loss 0.20344556058384727\n",
            "Epoch 62: Test loss 0.20204833430044677\n",
            "Epoch 63: Test loss 0.20067614248283006\n",
            "Epoch 64: Test loss 0.19932844101865557\n",
            "Epoch 65: Test loss 0.19800469726642334\n",
            "Epoch 66: Test loss 0.19670438996675818\n",
            "Epoch 67: Test loss 0.1954270091377124\n",
            "Epoch 68: Test loss 0.19417205595593157\n",
            "Epoch 69: Test loss 0.19293904262538042\n",
            "Epoch 70: Test loss 0.1917274922351921\n",
            "Epoch 71: Test loss 0.19053693860807636\n",
            "Epoch 72: Test loss 0.18936692614060308\n",
            "Epoch 73: Test loss 0.18821700963656637\n",
            "Epoch 74: Test loss 0.18708675413453119\n",
            "Epoch 75: Test loss 0.18597573473056647\n",
            "Epoch 76: Test loss 0.18488353639708086\n",
            "Epoch 77: Test loss 0.183809753798591\n",
            "Epoch 78: Test loss 0.18275399110517707\n",
            "Epoch 79: Test loss 0.1817158618043078\n",
            "Epoch 80: Test loss 0.18069498851165022\n",
            "Epoch 81: Test loss 0.17969100278141958\n",
            "Epoch 82: Test loss 0.17870354491676624\n",
            "Epoch 83: Test loss 0.17773226378064746\n",
            "Epoch 84: Test loss 0.17677681660758066\n",
            "Epoch 85: Test loss 0.17583686881663324\n",
            "Epoch 86: Test loss 0.17491209382596265\n",
            "Epoch 87: Test loss 0.17400217286918368\n",
            "Epoch 88: Test loss 0.17310679481380642\n",
            "Epoch 89: Test loss 0.17222565598195586\n",
            "Epoch 90: Test loss 0.1713584599735587\n",
            "Epoch 91: Test loss 0.1705049174921544\n",
            "Epoch 92: Test loss 0.16966474617346516\n",
            "Epoch 93: Test loss 0.16883767041683884\n",
            "Epoch 94: Test loss 0.16802342121965871\n",
            "Epoch 95: Test loss 0.16722173601479626\n",
            "Epoch 96: Test loss 0.16643235851116775\n",
            "Epoch 97: Test loss 0.1656550385374418\n",
            "Epoch 98: Test loss 0.1648895318889301\n",
            "Epoch 99: Test loss 0.16413560017768442\n",
            "0.17090415954589844 seconds elapsed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서플로우/케라스 이론 및 실습"
      ],
      "metadata": {
        "id": "FYldF4IOvY20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "FBBVmpSJctr7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "3EXoiFSmctt-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
        "x_train,x_test = x_train/225.0,x_test/225.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPXKdhtJctxY",
        "outputId": "26f97687-3ec3-4c7e-d7e8-fda6506de6fe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#등등 실습 간단히 진행"
      ],
      "metadata": {
        "id": "gGdoDCSMwRr4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor=>tensorflow의 기본 data type\n",
        "hello = tf.constant([3,3],dtype = tf.float32)\n",
        "print(hello)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpTRiVhTxH3w",
        "outputId": "90c3288f-74cd-4f94-8444-287d7701565b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([3. 3.], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant([[1.0,2.0],[3.0,4.0]])\n",
        "print(x)\n",
        "print(type(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLccrYLaxIUQ",
        "outputId": "700a51e1-4b37-49e2-ecc4-6abb42b35424"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 2.]\n",
            " [3. 4.]], shape=(2, 2), dtype=float32)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#np.array나 list도 tensor로 바꿀 수 있다.\n",
        "x_np = np.array([[1.0,2.0],\n",
        "                 [3.0,4.0]])\n",
        "x_np = tf.convert_to_tensor(x_np)\n",
        "print(type(x_np))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XsN3JerxIWK",
        "outputId": "8c1a9b84-91f7-4051-e978-85dd78ae1269"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor 를 np.array로 바꾸기\n",
        "x.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUtvkDtUxIXq",
        "outputId": "a348dd34-f3d9-43e9-f8cd-c4626ea3da93"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.ones((2,3))\n",
        "b = tf.zeros((2,3))\n",
        "c = tf.fill((2,3),2) #넘파이는 full\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "#like는 타입까지 가져옴\n",
        "d = tf.zeros_like(c)\n",
        "e = tf.ones_like(c)\n",
        "print(d)\n",
        "print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlkngWsUxIZB",
        "outputId": "0806aa29-5d6a-4a16-e186-1db4a205c5a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[2 2 2]\n",
            " [2 2 2]], shape=(2, 3), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0 0 0]\n",
            " [0 0 0]], shape=(2, 3), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 1 1]\n",
            " [1 1 1]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = tf.eye(3)\n",
        "print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb1cw9fGxIeX",
        "outputId": "1f1f5823-6ab4-4b9d-9bce-e91691aacc53"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = tf.range(10) #numpy에서는 arange\n",
        "print(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNep2S_8xIfn",
        "outputId": "d907df84-8413-4feb-f35e-5acfbeb0ccc7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = tf.random.uniform((2,2)) #np.rand 0-1사이\n",
        "i = tf.random.normal((2,2)) #np.randn\n",
        "print(h)\n",
        "print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQjh8MrOxIg8",
        "outputId": "fb481f1c-4031-4a24-d26e-ac1efa07190d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1.5556812e-04 8.5463905e-01]\n",
            " [8.6481702e-01 6.3538933e-01]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.14080335  0.20531832]\n",
            " [-0.49298513  0.2175819 ]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor의 속성 변\n",
        "tensor = tf.random.normal((3,4))\n",
        "tensor = tf.reshape(tensor,(4,3))\n",
        "tensor = tf.cast(tensor,tf.int32)\n",
        "\n",
        "print (tensor.shape)\n",
        "print(tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-vbl5r3xIkK",
        "outputId": "7652eec3-2299-42c6-ddbd-847231eae0ba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 3)\n",
            "<dtype: 'int32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#variable => 튜플같이 값 변경 불가\n",
        "tensor = tf.ones((3,4))\n",
        "v = tf.Variable(tensor)\n",
        "print(v)\n",
        "\n",
        "v[0,0].assign(2)\n",
        "print(v)\n",
        "\n",
        "#뺄셈\n",
        "add = tf.ones(shape = (3,4))\n",
        "v.assign_sub(add)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LToIEEq1Hd_",
        "outputId": "6a433d57-f702-45ae-a1bc-8c8412efc29b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float32, numpy=\n",
            "array([[1., 1., 1., 1.],\n",
            "       [1., 1., 1., 1.],\n",
            "       [1., 1., 1., 1.]], dtype=float32)>\n",
            "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float32, numpy=\n",
            "array([[2., 1., 1., 1.],\n",
            "       [1., 1., 1., 1.],\n",
            "       [1., 1., 1., 1.]], dtype=float32)>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(3, 4) dtype=float32, numpy=\n",
              "array([[1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#indexing과 slicing\n",
        "a = tf.range(1,13)\n",
        "a = tf.reshape(a,(3,4))\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9V96nCS12fe",
        "outputId": "f1ed388c-86d8-4702-9a38-bb001819ef00"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#indexing\n",
        "print(a[1])\n",
        "print(a[0,-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaWaiPG72Neu",
        "outputId": "432cbd36-d78f-4b27-9c08-253142bd7ae1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([5 6 7 8], shape=(4,), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#slicing\n",
        "print(a[1:-1])\n",
        "print(a[:2,2:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0AUKXD72NgV",
        "outputId": "21b76090-fc4b-4b02-8956-64be147cf776"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[5 6 7 8]], shape=(1, 4), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[3 4]\n",
            " [7 8]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.range(16)\n",
        "a = tf.reshape(a,(2,2,-1))\n",
        "print(a)\n",
        "\n",
        "b = tf.transpose(a,(2,0,1))\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uXM3CpT2Nhr",
        "outputId": "c7dba8f9-d9f2-4a9f-9c2f-3503c388969f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3]\n",
            "  [ 4  5  6  7]]\n",
            "\n",
            " [[ 8  9 10 11]\n",
            "  [12 13 14 15]]], shape=(2, 2, 4), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[[ 0  4]\n",
            "  [ 8 12]]\n",
            "\n",
            " [[ 1  5]\n",
            "  [ 9 13]]\n",
            "\n",
            " [[ 2  6]\n",
            "  [10 14]]\n",
            "\n",
            " [[ 3  7]\n",
            "  [11 15]]], shape=(4, 2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#축에 따라 덧셈\n",
        "z = tf.range(1,11)\n",
        "z = tf.reshape(z,(2,5))\n",
        "print(z)\n",
        "print(tf.reduce_sum(z,axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-93JUyK334H-",
        "outputId": "0f618a1e-28ca-441a-c78f-0a5d80bd4cfa"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1  2  3  4  5]\n",
            " [ 6  7  8  9 10]], shape=(2, 5), dtype=int32)\n",
            "tf.Tensor([ 7  9 11 13 15], shape=(5,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = tf.concat([z,z],axis=0)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqQ6ftFMCuQU",
        "outputId": "9e303141-f6be-41c7-9296-c92408bcc51b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1  2  3  4  5]\n",
            " [ 6  7  8  9 10]\n",
            " [ 1  2  3  4  5]\n",
            " [ 6  7  8  9 10]], shape=(4, 5), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset\n",
        "mnist = keras.datasets.fashion_mnist\n",
        "class_names = ['T-shirt/top','Trouser','Pellover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
        "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()\n",
        "unique,counts = np.unique(train_labels,axis=-1,return_counts=True)"
      ],
      "metadata": {
        "id": "9RPU4Za-DCTw"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(train_images[1],cmap='gray')\n",
        "  plt.title(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "etptBLjyDVZY",
        "outputId": "c232d114-59de-4296-c221-4290e1526383"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAKSCAYAAABMVtaZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVSklEQVR4nO3de3xU1b338e+QZHIPQe43ERDE4K0NKh65Y+FBwKJSAvUCAsJRsHpOOV7Oo0WqtKdKtdVWhD6niBZfgMpFPVzER7QiUrBoFVsEEWw0GoJCEm65zXr+4MU8DNlrZxKTmYT1eb9eebX57b32XjOZn/Njz/z2ChhjjAAAAHDGaxbvCQAAACA2KPwAAAAcQeEHAADgCAo/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHAEhR8AAIAjKPy+g0mTJikjI6PG/QYNGqRBgwbV23kHDRqkCy64oN6OBzQl+/btUyAQ0Lx582rc98EHH1QgEIjBrIAzD7l2ZnKu8HvqqacUCAR0+eWXx3sqTdIvfvELrVq1Kt7TQCMWCASi+nnzzTfjPdUIR48e1YMPPug7r4MHDyoxMVHLly+XRD4gvsg11EVivCcQa0uWLNE555yjrVu36tNPP9W5554b7yk1Kb/4xS80duxYjRkzJt5TQSP13HPPRfz+7LPPasOGDdXi559/foPP5f7779e9994b1b5Hjx7VnDlzJMl6hX79+vUKBAIaNmyYJPIB8UWuoS6cKvz27t2rzZs3a8WKFZo+fbqWLFmi2bNnx3tawBnlxhtvjPh9y5Yt2rBhQ7V4LCQmJiox0f8/c6FQSOXl5VEdb82aNbryyiuVnZ1dD7MDvhtyDXXh1Ee9S5YsUYsWLTRy5EiNHTtWS5YsqbbPqd9pWLhwobp3767k5GRdeuml2rZtW43n+OCDD9S6dWsNGjRIhw8ftu5XVlam2bNn69xzz1VycrI6d+6su+++W2VlZVE/nr/+9a/6l3/5F6Wmpqpr1656+umnq+2zf/9+TZkyRW3btlVKSoouvvhiLV68uNp+R44c0U9/+lN17txZycnJOu+88zRv3jwZY8L7BAIBHTlyRIsXLw5/hDBp0qSo5wtE47333tPw4cPVqlWr8Gt78uTJnvvWlKNe3zsKBAKaOXOmlixZot69eys5OVlPP/20WrduLUmaM2dO+PX94IMPhseFQiGtW7dOI0eODB/HLx/ef/99jRgxQllZWcrIyNDQoUO1ZcuWiLk888wzCgQC+vOf/6zp06erZcuWysrK0s0336yDBw/W9SkEokKuuZlrTl3xW7Jkia677joFg0FNmDBB8+fP17Zt23TppZdW2/f5559XaWmppk+frkAgoEceeUTXXXedPvvsMyUlJXkef9u2bRo+fLj69Omj1atXKzU11XO/UCika665Rps2bdK0adN0/vnn66OPPtLjjz+uXbt2RfU9hoMHD+rqq6/WuHHjNGHCBC1fvly33XabgsFgOHGPHTumQYMG6dNPP9XMmTPVtWtXvfDCC5o0aZIOHTqkO++8U5JkjNE111yjjRs3asqUKbrkkku0fv16/cd//Ie+/PJLPf7445JOfKwwdepUXXbZZZo2bZokqXv37jXOFYjW/v37NWzYMLVu3Vr33nuvsrOztW/fPq1YsaLavnXJ0ZPeeOMNLV++XDNnzlSrVq108cUXa/78+brtttt07bXX6rrrrpMkXXTRReEx27ZtU1FRka6++mpJ/vnw8ccfq3///srKytLdd9+tpKQkLViwQIMGDdJbb71V7TvGM2fOVHZ2th588EF98sknmj9/vj7//HO9+eabfGEeDYJcczjXjCPee+89I8ls2LDBGGNMKBQynTp1MnfeeWfEfnv37jWSTMuWLc23334bjq9evdpIMq+88ko4NnHiRJOenm6MMWbTpk0mKyvLjBw50hw/fjzimAMHDjQDBw4M//7cc8+ZZs2ambfffjtiv6efftpIMu+8847vYxk4cKCRZH7961+HY2VlZeaSSy4xbdq0MeXl5cYYY37zm98YSeZPf/pTeL/y8nJzxRVXmIyMDFNSUmKMMWbVqlVGknn44YcjzjN27FgTCATMp59+Go6lp6ebiRMn+s4PONWMGTNMtP+pWblypZFktm3bZt2nNjk6e/bsaueWZJo1a2Y+/vjjiHhRUZGRZGbPnu153gceeMB06dIlImbLhzFjxphgMGj27NkTjhUUFJjMzEwzYMCAcGzRokVGksnNzQ3nrTHGPPLII0aSWb16tfV5AE5Hrp1Arvlz5qPeJUuWqG3btho8eLCkE5eO8/LytHTpUlVVVVXbPy8vTy1atAj/3r9/f0nSZ599Vm3fjRs3avjw4Ro6dKhWrFih5ORk37m88MILOv/889WrVy8dOHAg/DNkyJDw8WqSmJio6dOnh38PBoOaPn269u/fr7/+9a+STnxHol27dpowYUJ4v6SkJP3kJz/R4cOH9dZbb4X3S0hI0E9+8pOIc/z0pz+VMUZr166tcT5AfTj5fZ5XX31VFRUVvvvWJkdPN3DgQOXk5NRqbmvWrAl/9OSnqqpKr732msaMGaNu3bqF4+3bt9ePf/xjbdq0SSUlJRFjpk2bFnHl5LbbblNiYqLWrFlTqzkC0SLXTnAx15wo/KqqqrR06VINHjxYe/fu1aeffqpPP/1Ul19+uQoLC/V//+//rTbm7LPPjvj95Iv+9O8CHD9+XCNHjtT3vvc9LV++XMFgsMb57N69Wx9//LFat24d8dOzZ09JJy7B16RDhw5KT0+PiJ0cv2/fPknS559/rh49eqhZs8g/88kOr88//zz8vx06dFBmZqbvfkB9OXz4sL7++uvwT1FRkaQTbxLXX3+95syZo1atWumHP/yhFi1a5Pnd12hz1EvXrl1rNd+vv/5a27dvj+rNqKioSEePHtV5551Xbdv555+vUCik/Pz8iHiPHj0ifs/IyFD79u3DuQzUFblGrp3OicLvjTfe0FdffaWlS5eqR48e4Z9x48ZJkmeTR0JCguexzCnNDpKUnJyskSNH6i9/+YvWrVsX1XxCoZAuvPBCbdiwwfPn9ttvr+UjBJqWefPmqX379uGfk9+zDQQCevHFF/Xuu+9q5syZ+vLLLzV58mTl5uZWa5aKNke92L5/a7N27VqlpKSEPzEAmgpyDadzorljyZIlatOmjX7/+99X27ZixQqtXLlSTz/9dK1foNKJ5FmyZIl++MMf6kc/+pHWrl1b4yod3bt319/+9jcNHTq0zl8mLSgo0JEjRyKu+u3atUuSdM4550iSunTpog8//FChUCjiqt/OnTvD20/+7+uvv67S0tKIq36n73fy8QLf1c0336x+/fqFfz899/r27au+fftq7ty5ev7553XDDTdo6dKlmjp1aoPNye+1/T//8z8aPHhwtXl6jWndurXS0tL0ySefVNu2c+dONWvWTJ07d46I7969O+KN7vDhw/rqq6/CX24H6opcI9dOd8Zf8Tt27JhWrFihUaNGaezYsdV+Zs6cqdLSUr388st1PkcwGNSKFSt06aWXavTo0dq6davv/uPGjdOXX36pP/zhD57zPXLkSI3nrKys1IIFC8K/l5eXa8GCBWrdurVyc3MlSVdffbW+/vprLVu2LGLck08+qYyMDA0cODC8X1VVlX73u99FnOPxxx9XIBDQiBEjwrH09HQdOnSoxvkBfrp166arrroq/HPllVdKOvHR0elXES655BJJqtWtjuoiLS1Nkqq9visqKrRhwwbPj5688iEhIUHDhg3T6tWrIz4+Kiws1PPPP69+/fopKysrYszChQsjvmc1f/58VVZWRuQeUBfkGrl2ujP+it/LL7+s0tJSXXPNNZ7b+/btq9atW2vJkiXKy8ur83lSU1P16quvasiQIRoxYoTeeust63q6N910k5YvX65//dd/1caNG3XllVeqqqpKO3fu1PLly7V+/Xr16dPH93wdOnTQr371K+3bt089e/bUsmXL9MEHH2jhwoXhL65OmzZNCxYs0KRJk/TXv/5V55xzjl588UW98847+s1vfhO+ujd69GgNHjxY//t//2/t27dPF198sV577TWtXr1ad911V8QtW3Jzc/X666/rscceU4cOHdS1a1eWv0O9Wbx4sZ566ilde+216t69u0pLS/WHP/xBWVlZDf4v8tTUVOXk5GjZsmXq2bOnzjrrLF1wwQUqKipSSUmJ55uRLR8efvhhbdiwQf369dPtt9+uxMRELViwQGVlZXrkkUeqHae8vFxDhw7VuHHj9Mknn+ipp55Sv379rP/dAr4rcs3hXItnS3EsjB492qSkpJgjR45Y95k0aZJJSkoyBw4cCLevP/roo9X202nt56fezuWkAwcOmJycHNOuXTuze/duY0z127kYc+K2Kr/61a9M7969TXJysmnRooXJzc01c+bMMcXFxb6PaeDAgaZ3797mvffeM1dccYVJSUkxXbp0Mb/73e+q7VtYWGhuueUW06pVKxMMBs2FF15oFi1aVG2/0tJS82//9m+mQ4cOJikpyfTo0cM8+uijJhQKRey3c+dOM2DAAJOammokcWsX1Kg2t5jYvn27mTBhgjn77LNNcnKyadOmjRk1apR57733wvvUJkdtt5iYMWOG5/k3b95scnNzTTAYDB9r1qxZJicnx3N/v3zYvn27GT58uMnIyDBpaWlm8ODBZvPmzRHjT95i4q233jLTpk0zLVq0MBkZGeaGG24w33zzTU1PFxCBXCPXohEwJopvZwKAo3JycjRq1CjPqwff1TPPPKNbbrlF27Ztq/EqP3CmI9di44z/qBcA6qq8vFx5eXnhOwAAaBjkWuxQ+AGARTAY1OzZs+M9DeCMR67Fzhnf1QsAAIAT+I4fAACAI7jiBwAA4AgKPwAAAEdE1dwRCoVUUFCgzMxMluzCGcEYo9LSUnXo0CFiObt4I9dwpiHXgNiINteiKvwKCgqqrXcHnAny8/PVqVOneE8jjFzDmYpcA2KjplyLqvA7ubSX63r06OEZnzdvnnXMqlWrPOMffvihdUx5ebln/NT1BU+Xk5PjGR81apR1zN69ez3jTzzxhHVMcXGxdVtT1Nhe241tPvFCrpFrDa2xzSdeyDX3ci2qwq8xXAb3m0OsGpMTEhI84+np6dYxwWCwVsfy2xYKhaxjTq7Pe7qTi2F7SUlJ8Yw3hr93rDS2x9oY5kOukWsNobE91sYwH3KNXGsINT3WxvOFCwAAADQoCj8AAABHRHUD55KSEjVv3rz+Thqjy9uXXHKJddv48eM949dff711TFVVlWfc75J4amqqZ7xly5bWMfVp165d1m22S+znnXeedUxhYaFnfP369dYxtu+K7NixwzomVoqLi5WVlRXvaYSRayeQa+RaQyPXTiDX3Ms1rvgBAAA4gsIPAADAERR+AAAAjqDwAwAAcASFHwAAgCMo/AAAABwRl9u51IVfa/Kzzz7rGb/ooousY2wLGJeWllrHHD9+3DPut+SMrVXedkdySdbn+siRI9Yxthb2+r77u+2u6Lb2fsl+l/e3337bOuamm26q3cTq6Ey/xURdkGvkWkMg16oj18i1hsDtXAAAACCJwg8AAMAZFH4AAACOoPADAABwBIUfAACAIxLjPYForVixwrqtS5cunvH9+/dbx9i6hRIT7U9JZWWlZ9xvcW7b8fzGHDhwwDOekJBgHWNj6/Kqq2PHjnnGbZ1hkr0Da8CAAdYxvXr18ozv3LnTZ3aoD+QauSaRa7FArpFrUuxzjSt+AAAAjqDwAwAAcASFHwAAgCMo/AAAABxB4QcAAOAICj8AAABHNLrbueTm5nrGba3tkr1N3K+F3dZCblusWZI6duzoGU9LS7OOsbWd+y2AbZu3bWFsyd5G77dotq2N329B7y+++KJWx/Lj93imTp3qGZ81a1atzwNv5Bq5JpFrsUCukWtS48k1rvgBAAA4gsIPAADAERR+AAAAjqDwAwAAcASFHwAAgCMaXVfv4MGDPePJycnWMbZttgWrJXv3U1lZmXXMPffc4xkvKCiwjrF1C3Xo0ME65quvvvKM+y1MXV5e7hn3e94yMjI849///vetY+644w7PuK0DTbJ3c/n9fcaOHesZp9Ow/pBr5JpErsUCuUauSY0n17jiBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwRMAYY2raqaSkRM2bN4/FfLRlyxbPeJs2baxjbIsv21rBJXvLd3FxsXVM3759PePDhg2zjrEtgL1o0SLrmOnTp3vGd+zYYR2TmprqGbe190tSYWGhZ/yDDz6wjtm9e7dn3G8BbNsC4X4LYPfq1cszfsEFF1jH7Nq1y7rNpri4WFlZWbUe11DItRPINXKtoZFrJ5Br7uUaV/wAAAAcQeEHAADgCAo/AAAAR1D4AQAAOILCDwAAwBHeqwzH0cUXX+wZz8/Pt46xLfLst5CzTV26ztatW2fdduTIEc94Tk6OdYxtweaVK1dax4wePdozbltIWpK2b9/uGc/NzbWOsXUspaenW8dUVVV5xv0Ws/7nP//pGb/iiiusY+rS/eQyco1ck8i1WCDXyDWp8eQaV/wAAAAcQeEHAADgCAo/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6Iy+1c/BYkLioq8oz7LXxsW7A5EAhYx9gWf/7mm2+sY2z8Hk9ZWZlnvH379tYxc+fO9Yz7PZ6Kiopaj/FrIbcpKCjwjNsW7Zbq1vZ+7Ngxz3j//v2tYxYvXmzd5ipyjVyTyLVYINfINalp5BpX/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAEXHp6r3nnnus22xdSYcPH7aOsXXX2I4lScePH/eM+3VZ9enTxzPesmVL65izzjrLM56UlGQd07ZtW8+4rcNJsj+eYDBoHZOdne0Zz8vLs45p0aKFZ9zWrSRJzZs3r/UY27xtfwN4I9fItZrGkGv1g1wj12oa01hyjSt+AAAAjqDwAwAAcASFHwAAgCMo/AAAABxB4QcAAOAICj8AAABHxOV2Lps3b7Zua9eunWf83HPPtY7JysryjKenp1vH7N692zNua6GXpC1btnjG/RZltm3zO49tce7ERPufy7Zotd95mjXzrvtLS0utY3bt2uUZT0tLs46xPR7b+SX7otmrVq2yjkF15Bq55nd+iVyrL+QaueZ3fqnx5BpX/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAEQFjjKlpp5KSEuuCxLFiW0RZknr06OEZv+2226xjBg4c6BnPz8+3jrE9B4cOHbKOsS1abesIqm+2rijJ3n1kWxhbsj8HH330kXXMDTfcYN0Wb8XFxdbuuXgg104g18i1hkaunUCuuZdrXPEDAABwBIUfAACAIyj8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADjCvjpyI3Pw4EHrtq1bt3rGy8rKrGOGDBniGfe7u00wGPSM+y2abWtv91sA28avhd22ze88ycnJnvHy8nLrmJSUFM+43wLlaFrINXINsUGukWvxwBU/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHBEo+vqtXXx2BaFluzdOn6dTCUlJZ5xv0Wmq6qqan0eG79Oprocrz7VZaFtvwW963IeW9dWvJ+bMwm5Fv/XE7nmBnIt/q8ncu3/44ofAACAIyj8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARje52Lra25oqKilofa8+ePdZttrb3xET7U+K3yLON7fHUd9u73/FsbI/H7xYDNrbn00+zZvZ/d9huMYD6Q66RaxK5FgvkGrkmNZ5c44ofAACAIyj8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADii0XX12tSlU+bYsWPWMbbOn+TkZOuYyspKz7hfx5StK8mvw8k2xq/Dyfb8+J2nrKzMM56WllbrudmeGzQ95Bq5htgg18i1eOCKHwAAgCMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAEU3mdi51WeA5FApZt9la5f3OY9vm15Jv4ze3hISEWh/P1o7uNzfb4/GbW13a62t7fsQXueaPXEN9Idf8kWsNgyt+AAAAjqDwAwAAcASFHwAAgCMo/AAAABxB4QcAAOCIJtPVW986duzoGT948KB1jK0rya+Lx9Yt5LcwdazY5lZRUWEdY5t3XTq24AZyjVxDbJBr5Fo0uOIHAADgCAo/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHBEk7mdS30vfFxZWVnrMcFg0DNuWxhbsreJ+7W927b5PQe2MX4LUyclJXnGy8rKrGNsc7Ady09TWMzaReQauYbYINfItXjgih8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR1D4AQAAOKLJdPXWN1uHj9+izLaOKb8xtu4jv84f2/HKy8utY2zHS0y0/4ltY44ePWodY5OdnV3rMXADuUauITbINXItGlzxAwAAcASFHwAAgCMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4wtnbufgt8lxbfgtT12XB5mbNvOtxv/PU5fx1WTTb1vqfmppau4nVcB6cOcg1cg2xQa6Ra9Hgih8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR1D4AQAAOMLZrl5bh1Fd1HcXT6y6n2znqUv3U1paWu0mBmeQa+QaYoNcI9eiwRU/AAAAR1D4AQAAOILCDwAAwBEUfgAAAI6g8AMAAHAEhR8AAIAjmsztXGK18HFCQkK9Hs8277q0sNdlbvW5mLYkVVVVecbr+3lD/JBr5Bpig1wj1+KBK34AAACOoPADAABwBIUfAACAIyj8AAAAHEHhBwAA4Igm09Xr1y1Ulw6f8vJyz3h9L8ocCoU8437dQrYFo+v7OaiL+ux+itWcUTvkGrmG2CDXyLV44IofAACAIyj8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARTeZ2LrFSl4Wc/drRbcfzO49tm62FvqY52Njazv3mZnOmLmaNhkOukWuIDXKNXDsVV/wAAAAcQeEHAADgCAo/AAAAR1D4AQAAOILCDwAAwBFNpqu3vhc+Ligo8Iz37NnTOsa2yLRfV5JtW1JSUq3H+J3H9vzYOrYkKTGx9n9+23nO1MWsXUSukWuIDXKNXIsHrvgBAAA4gsIPAADAERR+AAAAjqDwAwAAcASFHwAAgCMo/AAAABzRZG7nUt+ys7M94+np6dYxtjbxVq1aWcfUZTFrv5b42vJre7e1qufn51vHpKWleca7d+9eu4nJ/znwa/FH00KukWuIDXKNXIsGV/wAAAAcQeEHAADgCAo/AAAAR1D4AQAAOILCDwAAwBFNpqs3EAhYt9VlUeT333/fM/73v//dOubQoUOe8bp0K/l1/hw+fNgz7vc4bc+PbQFuyd5hVF5ebh3TokULz/jWrVutY2p7fsQXuUauITbINXItHrjiBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOiKqrty7dRfWtvudw/Phxz7hfR45tjN+6gTZ+3U9lZWWe8cbQ/WR7DioqKqxjGrPG8No+VWOYD7lGrjWExvDaPlVjmA+5Rq41hJpeVwETxSvviy++UOfOnettUkBjkZ+fr06dOsV7GmHkGs5U5BoQGzXlWlSFXygUUkFBgTIzM33vOwQ0FcYYlZaWqkOHDr7/So01cg1nGnINiI1ocy2qwg8AAABNX+P55xcAAAAaFIUfAACAIyj8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwBIUfAACAIyj8AAAAHEHhB6BJ2bdvnwKBgObNm1fjvg8++KACgUAMZgW4Y9KkSTrnnHMiYoFAQA8++GBc5oPaofD7Dp555hkFAoHwT0pKijp06KDhw4friSeeUGlpabynCMTcqTnh9/Pmm2/Ge6oRjh49qgcffNB3XgcPHlRiYqKWL18uSfrFL36hVatWxWaCwHfg9X7Vs2dPzZw5U4WFhfGeHmIoMd4TOBP8/Oc/V9euXVVRUaGvv/5ab775pu666y499thjevnll3XRRRfFe4pAzDz33HMRvz/77LPasGFDtfj555/f4HO5//77de+990a179GjRzVnzhxJ0qBBgzz3Wb9+vQKBgIYNGybpROE3duxYjRkzpj6mCzS4k+9Xx48f16ZNmzR//nytWbNGO3bsUFpaWrynhxig8KsHI0aMUJ8+fcK/33fffXrjjTc0atQoXXPNNfrHP/6h1NRUz7FHjhxRenp6rKYKNLgbb7wx4vctW7Zow4YN1eKxkJiYqMRE///MhUIhlZeXR3W8NWvW6Morr1R2dnY9zA6IvVPfr6ZOnaqWLVvqscce0+rVqzVhwoQ4z65hHD9+XMFgUM2a8SGnxEe9DWbIkCF64IEH9Pnnn+tPf/qTpBPfi8jIyNCePXt09dVXKzMzUzfccIOkE28+v/nNb9S7d2+lpKSobdu2mj59ug4ePBhx3Pfee0/Dhw9Xq1atlJqaqq5du2ry5MkR+yxdulS5ubnKzMxUVlaWLrzwQv32t7+NzQMHvqNoXuMnLVy4UN27d1dycrIuvfRSbdu2LWK713f8AoGAZs6cqSVLlqh3795KTk7W008/rdatW0uS5syZE/447NTvLIVCIa1bt04jR44MH+fIkSNavHhxeP9JkyaF93///fc1YsQIZWVlKSMjQ0OHDtWWLVsi5nLy47c///nPmj59ulq2bKmsrCzdfPPN1XIfaAhDhgyRJO3du1eS9Kc//Um5ublKTU3VWWedpfHjxys/P79Ox64pB9577z0FAgEtXry42tiTV9dfffXVcOzLL7/U5MmT1bZtWyUnJ6t379764x//GDHuzTffVCAQ0NKlS3X//ferY8eOSktLU0lJSZ0ew5mIK34N6KabbtJ//ud/6rXXXtOtt94qSaqsrNTw4cPVr18/zZs3L3xpffr06XrmmWd0yy236Cc/+Yn27t2r3/3ud3r//ff1zjvvKCkpSfv379ewYcPUunVr3XvvvcrOzta+ffu0YsWK8Dk3bNigCRMmaOjQofrVr34lSfrHP/6hd955R3feeWfsnwSgFqJ5jZ/0/PPPq7S0VNOnT1cgENAjjzyi6667Tp999pmSkpJ8z/PGG29o+fLlmjlzplq1aqWLL75Y8+fP12233aZrr71W1113nSRFfE1j27ZtKioq0tVXXy3pxEfaU6dO1WWXXaZp06ZJkrp37y5J+vjjj9W/f39lZWXp7rvvVlJSkhYsWKBBgwbprbfe0uWXXx4xn5kzZyo7O1sPPvigPvnkE82fP1+ff/55+E0MaCh79uyRJLVs2VJz587VAw88oHHjxmnq1KkqKirSk08+qQEDBuj999+v1ZXuaHKgT58+6tatm5YvX66JEydGjF+2bJlatGih4cOHS5IKCwvVt2/f8D/cWrdurbVr12rKlCkqKSnRXXfdFTH+oYceUjAY1KxZs1RWVqZgMPidnqczikGdLVq0yEgy27Zts+7TvHlz873vfc8YY8zEiRONJHPvvfdG7PP2228bSWbJkiUR8XXr1kXEV65cWeP57rzzTpOVlWUqKyvr+rCAejVjxgwT7X9qonmN792710gyLVu2NN9++204vnr1aiPJvPLKK+HY7Nmzq51bkmnWrJn5+OOPI+JFRUVGkpk9e7bneR944AHTpUuXiFh6erqZOHFitX3HjBljgsGg2bNnTzhWUFBgMjMzzYABA8Kxk/8Nyc3NNeXl5eH4I488YiSZ1atXW58HoDZOvtZef/11U1RUZPLz883SpUtNy5YtTWpqqtm3b59JSEgwc+fOjRj30UcfmcTExIj4xIkTq+XC6bkTbQ7cd999JikpKSKXy8rKTHZ2tpk8eXI4NmXKFNO+fXtz4MCBiPOOHz/eNG/e3Bw9etQYY8zGjRuNJNOtW7dwDJH4qLeBZWRkVOvuve222yJ+f+GFF9S8eXP94Ac/0IEDB8I/ubm5ysjI0MaNGyUp/K+tV199VRUVFZ7ny87O1pEjR7Rhw4b6fzBAA4vmNX5SXl6eWrRoEf69f//+kqTPPvusxvMMHDhQOTk5tZrbmjVrwh/z+qmqqtJrr72mMWPGqFu3buF4+/bt9eMf/1ibNm2q9rHTtGnTIq5S3nbbbUpMTNSaNWtqNUegJldddZVat26tzp07a/z48crIyNDKlSu1YsUKhUIhjRs3LuJ9qF27durRo0f4fSgatcmBvLw8VVRURFzVf+2113To0CHl5eVJkowxeumllzR69GgZYyLmN3z4cBUXF2v79u0Rc5g4caL1u/Wuo/BrYIcPH1ZmZmb498TERHXq1Clin927d6u4uFht2rRR69atI34OHz6s/fv3SzrxZnX99ddrzpw5atWqlX74wx9q0aJFKisrCx/r9ttvV8+ePTVixAh16tRJkydP1rp162LzYIEoHT58WF9//XX4p6ioSFJ0r/GTzj777IjfTxaB0Xw3rmvXrrWa79dff63t27dHVfgVFRXp6NGjOu+886ptO//88xUKhap9Z6pHjx4Rv2dkZKh9+/bat29freYJ1OT3v/+9NmzYoI0bN+rvf/+7PvvsMw0fPly7d++WMUY9evSo9j70j3/8I/w+FI3a5MDFF1+sXr16admyZeF9li1bplatWoW/f1hUVKRDhw5p4cKF1eZ2yy23SFK1+dU2x13Cd/wa0BdffKHi4mKde+654VhycnK1zqJQKKQ2bdpoyZIlnsc5+aXzQCCgF198UVu2bNErr7yi9evXa/Lkyfr1r3+tLVu2KCMjQ23atNEHH3yg9evXa+3atVq7dq0WLVqkm2++2fMLtEA8zJs3L3zrFEnq0qVL+MbMNb3GT0pISPA8tjGmxvPX9krA2rVrlZKSosGDB9dqHNDYXHbZZRF3oTgpFAopEAho7dq1nrl1au7Vt7y8PM2dO1cHDhxQZmamXn75ZU2YMCHckR8KhSSduGPA6d8FPOn026Zxtc+Owq8Bnbxv2ckvp9p0795dr7/+uq688sqoXqx9+/ZV3759NXfuXD3//PO64YYbtHTpUk2dOlWSFAwGNXr0aI0ePVqhUEi33367FixYoAceeCCiCAXi5eabb1a/fv3Cv5/+uq/pNd4Q/Joo/ud//keDBw+uNk+vMa1bt1ZaWpo++eSTatt27typZs2aqXPnzhHx3bt3RxSVhw8f1ldffRVuJAEaWvfu3WWMUdeuXdWzZ8/vdKza5kBeXp7mzJmjl156SW3btlVJSYnGjx8fcbzMzExVVVXpqquu+k5zAx/1Npg33nhDDz30kLp27Rq+ZYvNuHHjVFVVpYceeqjatsrKSh06dEjSiY+wTr+acckll0hS+KOwb775JmJ7s2bNwv8S8vq4DIiHbt266aqrrgr/XHnllZKie403lJMd9ifz7aSKigpt2LDB82Pe9PT0avsnJCRo2LBhWr16dcRHtYWFhXr++efVr18/ZWVlRYxZuHBhxHca58+fr8rKSo0YMeK7PSggStddd50SEhI0Z86cajlojKn23uKntjlw/vnn68ILL9SyZcu0bNkytW/fXgMGDIg43vXXX6+XXnpJO3bsqHa+k18VQXS44lcP1q5dq507d6qyslKFhYV64403tGHDBnXp0kUvv/yyUlJSfMcPHDhQ06dP1y9/+Ut98MEHGjZsmJKSkrR792698MIL+u1vf6uxY8dq8eLFeuqpp3Tttdeqe/fuKi0t1R/+8AdlZWWFrwxMnTpV3377rYYMGaJOnTrp888/15NPPqlLLrkkJislAN9FNK/xhpKamqqcnBwtW7ZMPXv21FlnnaULLrhARUVFKikp8Sz8cnNz9frrr+uxxx5Thw4d1LVrV11++eV6+OGHtWHDBvXr10+33367EhMTtWDBApWVlemRRx6pdpzy8nINHTpU48aN0yeffKKnnnpK/fr10zXXXNOgjxk4qXv37nr44Yd13333ad++fRozZowyMzO1d+9erVy5UtOmTdOsWbOiPl5tcyAvL08/+9nPlJKSoilTplT7StR//dd/aePGjbr88st16623KicnR99++622b9+u119/Xd9+++13fg6cEbd+4jPAyfb4kz/BYNC0a9fO/OAHPzC//e1vTUlJScT+EydONOnp6dbjLVy40OTm5prU1FSTmZlpLrzwQnP33XebgoICY4wx27dvNxMmTDBnn322SU5ONm3atDGjRo0y7733XvgYL774ohk2bJhp06aNCQaD5uyzzzbTp083X331VcM8CUANanM7l2he4ydv5/Loo49WG6/Tbilhu53LjBkzPM+/efNmk5uba4LBYPhYs2bNMjk5OZ7779y50wwYMMCkpqYaSRG3dtm+fbsZPny4ycjIMGlpaWbw4MFm8+bNEeNP/jfkrbfeMtOmTTMtWrQwGRkZ5oYbbjDffPNNTU8XELVobj9mjDEvvfSS6devn0lPTzfp6emmV69eZsaMGeaTTz4J7xPN7VyMiS4HTtq9e3f4vXTTpk2e+xQWFpoZM2aYzp07m6SkJNOuXTszdOhQs3DhwvA+J2/n8sILL/g+TpcFjInim9AA4KicnByNGjXK8yrFd3Xypu3btm3z/MI9ANQ3PuoFAIvy8nLl5eVp3Lhx8Z4KANQLCj8AsAgGg5o9e3a8pwEA9YauXgAAAEfwHT8AAABHcMUPAADAERR+AAAAjoiquSMUCqmgoECZmZm+yxoBTYUxRqWlperQoUO1G4XGE7mGMw25BsRGtLkWVeFXUFBQbW1J4EyQn5+vTp06xXsaYeQazlTkGhAbNeVaVIVfZmZmvU2oKevRo4dnfN68edYxq1at8ox/+OGH1jHl5eWe8VPX8jxdTk6OZ3zUqFHWMXv37vWMP/HEE9YxxcXF1m1NUWN7bTe2+cQLuUauNbTGNp94Idfcy7WoCr/GcBncbw6xakxOSEjwjKenp1vHBIPBWh3Lb1soFLKOSUpK8oyfXHjei20N4cbw946VxvZYG8N8yDVyrSE0tsfaGOZDrpFrDaGmx9p4vnABAACABkXhBwAA4AgKPwAAAEdEtXJHSUmJmjdvXn8njdH3Gi655BLrtvHjx3vGr7/+euuYqqoqz7jfdyFSU1M94y1btrSOqU+7du2ybrN9t+K8886zjiksLPSMr1+/3jrG9iXhHTt2WMfESnFxsbKysuI9jTBy7QRyjVxraOTaCeSae7nGFT8AAABHUPgBAAA4gsIPAADAERR+AAAAjqDwAwAAcASFHwAAgCPicjuXuvBrTX722Wc94xdddJF1TLNm3jVvaWmpdczx48c9435rDdpa5W1L0UiyPtdHjhyxjrG1sNf3sj+25XBs7f2SfXmft99+2zrmpptuqt3E6uhMv8VEXZBr5FpDINeqI9fItYbA7VwAAAAgicIPAADAGRR+AAAAjqDwAwAAcASFHwAAgCMS4z2BaK1YscK6rUuXLp7x/fv3W8fYuoUSE+1PSWVlpWfcb3Fu2/H8xhw4cMAznpCQYB1jY+vyqqtjx455xm2dYZK9A2vAgAHWMb169fKM79y502d2qA/kGrkmkWuxQK6Ra1Lsc40rfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAcQeEHAADgCAo/AAAARzS627nk5uZ6xm2t7ZK9Tdyvhd3WQm5brFmSOnbs6BlPS0uzjrG1nfstgG2bt21hbMneRu+3aLatjd9vQe8vvviiVsfy4/d4pk6d6hmfNWtWrc8Db+QauSaRa7FArpFrUuPJNa74AQAAOILCDwAAwBEUfgAAAI6g8AMAAHAEhR8AAIAjGl1X7+DBgz3jycnJ1jG2bbYFqyV791NZWZl1zD333OMZLygosI6xdQt16NDBOuarr77yjPstTF1eXu4Z93veMjIyPOPf//73rWPuuOMOz7itA02yd3P5/X3Gjh3rGafTsP6Qa+SaRK7FArlGrkmNJ9e44gcAAOAICj8AAABHUPgBAAA4gsIPAADAERR+AAAAjqDwAwAAcETAGGNq2qmkpETNmzePxXy0ZcsWz3ibNm2sY2yLL9tawSV7y3dxcbF1TN++fT3jw4YNs46xLYC9aNEi65jp06d7xnfs2GEdk5qa6hm3tfdLUmFhoWf8gw8+sI7ZvXu3Z9xvAWzbAuF+C2D36tXLM37BBRdYx+zatcu6zaa4uFhZWVm1HtdQyLUTyDVyraGRayeQa+7lGlf8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMAR3qsMx9HFF1/sGc/Pz7eOsS3y7LeQs01dus7WrVtn3XbkyBHPeE5OjnWMbcHmlStXWseMHj3aM25bSFqStm/f7hnPzc21jrF1LKWnp1vHVFVVecb9FrP+5z//6Rm/4oorrGPq0v3kMnKNXJPItVgg18g1qfHkGlf8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOiMvtXPwWJC4qKvKM+y18bFuwORAIWMfYFn/+5ptvrGNs/B5PWVmZZ7x9+/bWMXPnzvWM+z2eioqKWo/xayG3KSgo8IzbFu2W6tb2fuzYMc94//79rWMWL15s3eYqco1ck8i1WCDXyDWpaeQaV/wAAAAcQeEHAADgCAo/AAAAR1D4AQAAOILCDwAAwBFx6eq95557rNtsXUmHDx+2jrF119iOJUnHjx/3jPt1WfXp08cz3rJlS+uYs846yzOelJRkHdO2bVvPuK3DSbI/nmAwaB2TnZ3tGc/Ly7OOadGihWfc1q0kSc2bN6/1GNu8bX8DeCPXyLWaxpBr9YNcI9dqGtNYco0rfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR8Tldi6bN2+2bmvXrp1n/Nxzz7WOycrK8oynp6dbx+zevdszbmuhl6QtW7Z4xv0WZbZt8zuPbXHuxET7n8u2aLXfeZo18677S0tLrWN27drlGU9LS7OOsT0e2/kl+6LZq1atso5BdeQaueZ3folcqy/kGrnmd36p8eQaV/wAAAAcQeEHAADgCAo/AAAAR1D4AQAAOILCDwAAwBEBY4ypaaeSkhLrgsSxYltEWZJ69OjhGb/tttusYwYOHOgZz8/Pt46xPQeHDh2yjrEtWm3rCKpvtq4oyd59ZFsYW7I/Bx999JF1zA033GDdFm/FxcXW7rl4INdOINfItYZGrp1ArrmXa1zxAwAAcASFHwAAgCMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4wr46ciNz8OBB67atW7d6xsvKyqxjhgwZ4hn3u7tNMBj0jPstmm1rb/dbANvGr4Xdts3vPMnJyZ7x8vJy65iUlBTPuN8C5WhayDVyDbFBrpFr8cAVPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwRKPr6rV18dgWhZbs3Tp+nUwlJSWecb9Fpquqqmp9Hhu/Tqa6HK8+1WWhbb8FvetyHlvXVryfmzMJuRb/1xO55gZyLf6vJ3Lt/+OKHwAAgCMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAEY3udi62tuaKiopaH2vPnj3Wbba298RE+1Pit8izje3x1Hfbu9/xbGyPx+8WAza259NPs2b2f3fYbjGA+kOukWsSuRYL5Bq5JjWeXOOKHwAAgCMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4otF19drUpVPm2LFj1jG2zp/k5GTrmMrKSs+4X8eUrSvJr8PJNsavw8n2/Pidp6yszDOelpZW67nZnhs0PeQauYbYINfItXjgih8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR1D4AQAAOILCDwAAwBFN5nYudVngORQKWbfZWuX9zmPb5teSb+M3t4SEhFofz9aO7jc32+Pxm1td2utre37EF7nmj1xDfSHX/JFrDYMrfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAcQeEHAADgiCbT1VvfOnbs6Bk/ePCgdYytK8mvi8fWLeS3MHWs2OZWUVFhHWObd106tuAGco1cQ2yQa+RaNLjiBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwRJO5nUt9L3xcWVlZ6zHBYNAzblsYW7K3ifu1vdu2+T0HtjF+C1MnJSV5xsvKyqxjbHOwHctPU1jM2kXkGrmG2CDXyLV44IofAACAIyj8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADiiyXT11jdbh4/fosy2jim/MbbuI7/OH9vxysvLrWNsx0tMtP+JbWOOHj1qHWOTnZ1d6zFwA7lGriE2yDVyLRpc8QMAAHAEhR8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR1D4AQAAOMLZ27n4LfJcW34LU9dlweZmzbzrcb/z1OX8dVk029b6n5qaWruJ1XAenDnINXINsUGukWvR4IofAACAIyj8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADjC2a5eW4dRXdR3F0+sup9s56lL91NaWlrtJgZnkGvkGmKDXCPXosEVPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwBIUfAACAI5rM7VxitfBxQkJCvR7PNu+6tLDXZW71uZi2JFVVVXnG6/t5Q/yQa+QaYoNcI9figSt+AAAAjqDwAwAAcASFHwAAgCMo/AAAABxB4QcAAOCIJtPV69ctVJcOn/Lycs94fS/KHAqFPON+3UK2BaPr+zmoi/rsforVnFE75Bq5htgg18i1eOCKHwAAgCMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAEU3mdi6xUpeFnP3a0W3H8zuPbZuthb6mOdjY2s795mZzpi5mjYZDrpFriA1yjVw7FVf8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARTaart74XPi4oKPCM9+zZ0zrGtsi0X1eSbVtSUlKtx/idx/b82Dq2JCkxsfZ/ftt5ztTFrF1ErpFriA1yjVyLB674AQAAOILCDwAAwBEUfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAc0WRu51LfsrOzPePp6enWMbY28VatWlnH1GUxa7+W+Nrya3u3tarn5+dbx6SlpXnGu3fvXruJyf858GvxR9NCrpFriA1yjVyLBlf8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADiCwg8AAMARTaarNxAIWLfVZVHk999/3zP+97//3Trm0KFDnvG6dCv5df4cPnzYM+73OG3Pj20BbsneYVReXm4d06JFC8/41q1brWNqe37EF7lGriE2yDVyLR644gcAAOAICj8AAABHUPgBAAA4gsIPAADAERR+AAAAjoiqq7cu3UX1rb7ncPz4cc+4X0eObYzfuoE2ft1PZWVlnvHG0P1kew4qKiqsYxqzxvDaPlVjmA+5Rq41hMbw2j5VY5gPuUauNYSaXlcBE8Ur74svvlDnzp3rbVJAY5Gfn69OnTrFexph5BrOVOQaEBs15VpUhV8oFFJBQYEyMzN97zsENBXGGJWWlqpDhw6+/0qNNXINZxpyDYiNaHMtqsIPAAAATV/j+ecXAAAAGhSFHwAAgCMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAERR+AAAAjqDwAwAAcASFHwAAgCMo/AAAABxB4dfE7Nu3T4FAQPPmzYv3VIBGZdKkSTrnnHMiYoFAQA8++GBc5gMges8884wCgYD27dtX67FeuQ87Cj8PH330kcaOHasuXbooJSVFHTt21A9+8AM9+eST8Z4acEY5+R/7kz8pKSnq2bOnZs6cqcLCwnhPDzij8V7npsR4T6Cx2bx5swYPHqyzzz5bt956q9q1a6f8/Hxt2bJFv/3tb3XHHXfEe4rAGefnP/+5unbtquPHj2vTpk2aP3++1qxZox07digtLS3e0wPOOLzXuYvC7zRz585V8+bNtW3bNmVnZ0ds279/f3wmFWNHjx7lzRYxNWLECPXp00eSNHXqVLVs2VKPPfaYVq9erQkTJsR5dg3j+PHjCgaDataMD14Qe7zXuYv/4pxmz5496t27d7VEkKQ2bdqE/38gENDMmTO1atUqXXDBBUpOTlbv3r21bt26auO+/PJLTZ48WW3btg3v98c//jFin/Lycv3sZz9Tbm6umjdvrvT0dPXv318bN26scc7GGE2bNk3BYFArVqwIx//0pz8pNzdXqampOuusszR+/Hjl5+dHjB00aJAuuOAC/fWvf9WAAQOUlpam//zP/6zxnEBDGjJkiCRp7969kqJ7LUfr/fff14gRI5SVlaWMjAwNHTpUW7ZsCW9/7733FAgEtHjx4mpj169fr0AgoFdffTUciya/33zzTQUCAS1dulT333+/OnbsqLS0NJWUlNTpMQDfVbTvdYsWLdKQIUPUpk0bJScnKycnR/Pnz6825pxzztGoUaO0adMmXXbZZUpJSVG3bt307LPPVtv3448/1pAhQ5SamqpOnTrp4YcfVigUqrbf6tWrNXLkSHXo0EHJycnq3r27HnroIVVVVX23B+84rvidpkuXLnr33Xe1Y8cOXXDBBb77btq0SStWrNDtt9+uzMxMPfHEE7r++uv1z3/+Uy1btpQkFRYWqm/fvuFCsXXr1lq7dq2mTJmikpIS3XXXXZKkkpIS/Z//8380YcIE3XrrrSotLdV///d/a/jw4dq6dasuueQSzzlUVVVp8uTJWrZsmVauXKmRI0dKOvGvuQceeEDjxo3T1KlTVVRUpCeffFIDBgzQ+++/H5Hs33zzjUaMGKHx48frxhtvVNu2bb/z8wh8F3v27JEktWzZslav5Zp8/PHH6t+/v7KysnT33XcrKSlJCxYs0KBBg/TWW2/p8ssvV58+fdStWzctX75cEydOjBi/bNkytWjRQsOHD5cUfX6f9NBDDykYDGrWrFkqKytTMBj8Ts8TUFfRvtfNnz9fvXv31jXXXKPExES98soruv322xUKhTRjxoyIfT/99FONHTtWU6ZM0cSJE/XHP/5RkyZNUm5urnr37i1J+vrrrzV48GBVVlbq3nvvVXp6uhYuXKjU1NRq537mmWeUkZGhf//3f1dGRobeeOMN/exnP1NJSYkeffTR+n1CXGIQ4bXXXjMJCQkmISHBXHHFFebuu+8269evN+Xl5RH7STLBYNB8+umn4djf/vY3I8k8+eST4diUKVNM+/btzYEDByLGjx8/3jRv3twcPXrUGGNMZWWlKSsri9jn4MGDpm3btmby5Mnh2N69e40k8+ijj5qKigqTl5dnUlNTzfr168P77Nu3zyQkJJi5c+dGHO+jjz4yiYmJEfGBAwcaSebpp5+u7VMFfGeLFi0ykszrr79uioqKTH5+vlm6dKlp2bKlSU1NrdVreeLEiaZLly4R+0kys2fPDv8+ZswYEwwGzZ49e8KxgoICk5mZaQYMGBCO3XfffSYpKcl8++234VhZWZnJzs6OyMdo83vjxo1GkunWrVs4BsRTtO91Xq/X4cOHm27dukXEunTpYiSZP//5z+HY/v37TXJysvnpT38ajt11111GkvnLX/4SsV/z5s2NJLN3717fc0+fPt2kpaWZ48ePh2NeuQ87Puo9zQ9+8AO9++67uuaaa/S3v/1NjzzyiIYPH66OHTvq5Zdfjtj3qquuUvfu3cO/X3TRRcrKytJnn30m6cRHsC+99JJGjx4tY4wOHDgQ/hk+fLiKi4u1fft2SVJCQkL4X/+hUEjffvutKisr1adPn/A+pyovL9ePfvQjvfrqq1qzZo2GDRsW3rZixQqFQiGNGzcu4pzt2rVTjx49qn18nJycrFtuuaV+nkCgDq666iq1bt1anTt31vjx45WRkaGVK1fW+rXsp6qqSq+99prGjBmjbt26hePt27fXj3/8Y23atCn80WteXp4qKioivjrx2muv6dChQ8rLy5NUu/w+aeLEiZ5XNoBYi/a97tTXa3FxsQ4cOKCBAwfqs88+U3FxccQxc3Jy1L9///DvrVu31nnnnRd+T5SkNWvWqG/fvrrssssi9rvhhhuqzfHUc5eWlurAgQPq37+/jh49qp07d363J8BhfNTr4dJLL9WKFStUXl6uv/3tb1q5cqUef/xxjR07Vh988IFycnIkSWeffXa1sS1atNDBgwclSUVFRTp06JAWLlyohQsXep7r1C/RLl68WL/+9a+1c+dOVVRUhONdu3atNu6Xv/ylDh8+rLVr12rQoEER23bv3i1jjHr06OF5zqSkpIjfO3bsyEdOiKvf//736tmzpxITE9W2bVudd955atasmVavXl2r17KfoqIiHT16VOedd161beeff75CoZDy8/PVu3dvXXzxxerVq5eWLVumKVOmSDrxMW+rVq3C3z+sbX5L3rkMxEs073XvvPOOZs+erXfffVdHjx6NGF9cXKzmzZuHf6/pPVGSPv/8c11++eXV9vPKy48//lj333+/3njjjWrfhz296ET0KPx8BINBXXrppbr00kvVs2dP3XLLLXrhhRc0e/ZsSSeu0nkxxkhS+MuqN954Y7XvCp100UUXSTrx5fVJkyZpzJgx+o//+A+1adNGCQkJ+uUvfxn+vtOphg8frnXr1umRRx7RoEGDlJKSEt4WCoUUCAS0du1azzlmZGRE/M4VCMTbZZddFu7qPVVtX8v1KS8vT3PnztWBAweUmZmpl19+WRMmTFBiYmJ4blJ0+X0SuYbGyPZed+ONN2ro0KHq1auXHnvsMXXu3FnBYFBr1qzR448/Xq0ho6b3xNo4dOiQBg4cqKysLP385z9X9+7dlZKSou3bt+uee+7xbAZBdCj8onTyTemrr76Kekzr1q2VmZmpqqoqXXXVVb77vvjii+rWrZtWrFihQCAQjp8sMk/Xt29f/eu//qtGjRqlH/3oR1q5cmX4Dal79+4yxqhr167q2bNn1PMFGpv6fC23bt1aaWlp+uSTT6pt27lzp5o1a6bOnTuHY3l5eZozZ45eeukltW3bViUlJRo/fnzE8aLNb6CpOPW97pVXXlFZWZlefvnliKt5tfmKxem6dOmi3bt3V4ufnpdvvvmmvvnmG61YsUIDBgwIx092+qPu+I7faTZu3Oj5r5M1a9ZI8r4cbZOQkKDrr79eL730knbs2FFte1FRUcS+UuS/jP7yl7/o3XfftR7/qquu0tKlS7Vu3TrddNNN4X8BXXfddUpISNCcOXOqPRZjjL755puoHwMQT/X5Wk5ISNCwYcO0evXqiGWhCgsL9fzzz6tfv37KysoKx88//3xdeOGFWrZsmZYtW6b27dtHvAHVJr+Bxiaa9zqv96Xi4mItWrSozue9+uqrtWXLFm3dujUcKyoq0pIlSyL28zp3eXm5nnrqqTqfGydwxe80d9xxh44ePaprr71WvXr1Unl5uTZv3qxly5bpnHPOqXUTxH/9139p48aNuvzyy3XrrbcqJydH3377rbZv367XX39d3377rSRp1KhRWrFiha699lqNHDlSe/fu1dNPP62cnBwdPnzYevwxY8Zo0aJFuvnmm5WVlaUFCxaoe/fuevjhh3Xfffdp3759GjNmjDIzM7V3716tXLlS06ZN06xZs77T8wTEQn2/lh9++GFt2LBB/fr10+23367ExEQtWLBAZWVleuSRR6rtn5eXp5/97GdKSUnRlClTqt1sOdr8BhqbaN7rCgsLFQwGNXr0aE2fPl2HDx/WH/7wB7Vp06ZWn36d6u6779Zzzz2n//W//pfuvPPO8O1cunTpog8//DC837/8y7+oRYsWmjhxon7yk58oEAjoueeeq9PHxjhNbJuIG7+1a9eayZMnm169epmMjAwTDAbNueeea+644w5TWFgY3k+SmTFjRrXxXbp0MRMnToyIFRYWmhkzZpjOnTubpKQk065dOzN06FCzcOHC8D6hUMj84he/MF26dDHJycnme9/7nnn11VertamfejuXUz311FNGkpk1a1Y49tJLL5l+/fqZ9PR0k56ebnr16mVmzJhhPvnkk/A+AwcONL17967r0wV8Jydv57Jt2zbf/aJ5LUdzOxdjjNm+fbsZPny4ycjIMGlpaWbw4MFm8+bNnufdvXu3kWQkmU2bNnnuE01+n7ydywsvvOD7OIFYifa97uWXXzYXXXSRSUlJMeecc4751a9+Zf74xz9Wu/VKly5dzMiRI6udZ+DAgWbgwIERsQ8//NAMHDjQpKSkmI4dO5qHHnrI/Pd//3e1Y77zzjumb9++JjU11XTo0CF8yxlJZuPGjeH9uJ1L7QSMoXwGAABwAd/xAwAAcASFHwAAgCMo/AAAABxB4QcAAOAICj8AAABHUPgBAAA4IqobOIdCIRUUFCgzMzNiOTGgqTLGqLS0VB06dKh2U954ItdwpiHXgNiINteiKvwKCgoi1rAEzhT5+fnq1KlTvKcRRq7hTEWuAbFRU65FVfhlZmbW24Sash49enjG582bZx2zatUqz/ipS9Ocrry83DNeUVFhHZOTk+MZHzVqlHWMbbHrJ554wjqmuLjYuq0pamyv7cY2n3gh18i1htbY5hMv5Jp7uRZV4dcYLoP7zSFWi4+cXDT6dOnp6dYxwWCwVsfy2xYKhaxjkpKSPONpaWnWMSkpKZ7xxvD3jpXG9lgbw3zINXKtITS2x9oY5kOukWsNoabH2ni+cAEAAIAGReEHAADgiICJ4npySUmJmjdvXn8njdHl7UsuucS6bfz48Z7x66+/3jqmqqrKM+53STw1NdUz3rJlS+uY+rRr1y7rNtsl9vPOO886prCw0DO+fv166xjbd0V27NhhHRMrxcXFysrKivc0wsi1E8g1cq2hkWsnkGvu5RpX/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAERR+AAAAjojL7Vzqwq81+dlnn/WMX3TRRdYxtgWMS0tLrWOOHz/uGfdbcsbWKm+7I7kk63N95MgR6xhbC3t93/3ddld0W3u/ZL/L+9tvv20dc9NNN9VuYnV0pt9ioi7INXKtIZBr1ZFr5FpD4HYuAAAAkEThBwAA4AwKPwAAAEdQ+AEAADiCwg8AAMARifGeQLRWrFhh3dalSxfP+P79+61jbN1CiYn2p6SystIz7rc4t+14fmMOHDjgGU9ISLCOsbF1edXVsWPHPOO2zjDJ3oE1YMAA65hevXp5xnfu3OkzO9QHco1ck8i1WCDXyDUp9rnGFT8AAABHUPgBAAA4gsIPAADAERR+AAAAjqDwAwAAcASFHwAAgCMa3e1ccnNzPeO21nbJ3ibu18JuayG3LdYsSR07dvSMp6WlWcfY2s79FsC2zdu2MLZkb6P3WzTb1sbvt6D3F198Uatj+fF7PFOnTvWMz5o1q9bngTdyjVyTyLVYINfINanx5BpX/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAEY2uq3fw4MGe8eTkZOsY2zbbgtWSvfuprKzMOuaee+7xjBcUFFjH2LqFOnToYB3z1Vdfecb9FqYuLy/3jPs9bxkZGZ7x73//+9Yxd9xxh2fc1oEm2bu5/P4+Y8eO9YzTaVh/yDVyTSLXYoFcI9ekxpNrXPEDAABwBIUfAACAIyj8AAAAHEHhBwAA4AgKPwAAAEdQ+AEAADgiYIwxNe1UUlKi5s2bx2I+2rJli2e8TZs21jG2xZdtreCSveW7uLjYOqZv376e8WHDhlnH2BbAXrRokXXM9OnTPeM7duywjklNTfWM29r7JamwsNAz/sEHH1jH7N692zPutwC2bYFwvwWwe/Xq5Rm/4IILrGN27dpl3WZTXFysrKysWo9rKOTaCeQaudbQyLUTyDX3co0rfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAcQeEHAADgCO9VhuPo4osv9ozn5+dbx9gWefZbyNmmLl1n69ats247cuSIZzwnJ8c6xrZg88qVK61jRo8e7Rm3LSQtSdu3b/eM5+bmWsfYOpbS09OtY6qqqjzjfotZ//Of//SMX3HFFdYxdel+chm5Rq5J5FoskGvkmtR4co0rfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR8Tldi5+CxIXFRV5xv0WPrYt2BwIBKxjbIs/f/PNN9YxNn6Pp6yszDPevn1765i5c+d6xv0eT0VFRa3H+LWQ2xQUFHjGbYt2S3Vrez927JhnvH///tYxixcvtm5zFblGrknkWiyQa+Sa1DRyjSt+AAAAjqDwAwAAcASFHwAAgCMo/AAAABxB4QcAAOCIuHT13nPPPdZttq6kw4cPW8fYumtsx5Kk48ePe8b9uqz69OnjGW/ZsqV1zFlnneUZT0pKso5p27atZ9zW4STZH08wGLSOyc7O9ozn5eVZx7Ro0cIzbutWkqTmzZvXeoxt3ra/AbyRa+RaTWPItfpBrpFrNY1pLLnGFT8AAABHUPgBAAA4gsIPAADAERR+AAAAjqDwAwAAcASFHwAAgCPicjuXzZs3W7e1a9fOM37uuedax2RlZXnG09PTrWN2797tGbe10EvSli1bPON+izLbtvmdx7Y4d2Ki/c9lW7Ta7zzNmnnX/aWlpdYxu3bt8oynpaVZx9gej+38kn3R7FWrVlnHoDpyjVzzO79ErtUXco1c8zu/1HhyjSt+AAAAjqDwAwAAcASFHwAAgCMo/AAAABxB4QcAAOCIgDHG1LRTSUmJdUHiWLEtoixJPXr08Izfdttt1jEDBw70jOfn51vH2J6DQ4cOWcfYFq22dQTVN1tXlGTvPrItjC3Zn4OPPvrIOuaGG26wbou34uJia/dcPJBrJ5Br5FpDI9dOINfcyzWu+AEAADiCwg8AAMARFH4AAACOoPADAABwBIUfAACAIyj8AAAAHGFfHbmROXjwoHXb1q1bPeNlZWXWMUOGDPGM+93dJhgMesb9Fs22tbf7LYBt49fCbtvmd57k5GTPeHl5uXVMSkqKZ9xvgXI0LeQauYbYINfItXjgih8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR1D4AQAAOKLRdfXaunhsi0JL9m4dv06mkpISz7jfItNVVVW1Po+NXydTXY5Xn+qy0Lbfgt51OY+tayvez82ZhFyL/+uJXHMDuRb/1xO59v9xxQ8AAMARFH4AAACOoPADAABwBIUfAACAIyj8AAAAHEHhBwAA4IhGdzsXW1tzRUVFrY+1Z88e6zZb23tiov0p8Vvk2cb2eOq77d3veDa2x+N3iwEb2/Ppp1kz+787bLcYQP0h18g1iVyLBXKNXJMaT65xxQ8AAMARFH4AAACOoPADAABwBIUfAACAIyj8AAAAHNHounpt6tIpc+zYMesYW+dPcnKydUxlZaVn3K9jytaV5NfhZBvj1+Fke378zlNWVuYZT0tLq/XcbM8Nmh5yjVxDbJBr5Fo8cMUPAADAERR+AAAAjqDwAwAAcASFHwAAgCMo/AAAABxB4QcAAOCIJnM7l7os8BwKhazbbK3yfuexbfNrybfxm1tCQkKtj2drR/ebm+3x+M2tLu31tT0/4otc80euob6Qa/7ItYbBFT8AAABHUPgBAAA4gsIPAADAERR+AAAAjqDwAwAAcEST6eqtbx07dvSMHzx40DrG1pXk18Vj6xbyW5g6Vmxzq6iosI6xzbsuHVtwA7lGriE2yDVyLRpc8QMAAHAEhR8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR1D4AQAAOKLJ3M6lvhc+rqysrPWYYDDoGbctjC3Z28T92t5t2/yeA9sYv4Wpk5KSPONlZWXWMbY52I7lpyksZu0ico1cQ2yQa+RaPHDFDwAAwBEUfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAc0WS6euubrcPHb1FmW8eU3xhb95Ff54/teOXl5dYxtuMlJtr/xLYxR48etY6xyc7OrvUYuIFcI9cQG+QauRYNrvgBAAA4gsIPAADAERR+AAAAjqDwAwAAcASFHwAAgCMo/AAAABzh7O1c/BZ5ri2/hanrsmBzs2be9bjfeepy/rosmm1r/U9NTa3dxGo4D84c5Bq5htgg18i1aHDFDwAAwBEUfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAc4WxXr63DqC7qu4snVt1PtvPUpfspLS2tdhODM8g1cg2xQa6Ra9Hgih8AAIAjKPwAAAAcQeEHAADgCAo/AAAAR1D4AQAAOILCDwAAwBFN5nYusVr4OCEhoV6PZ5t3XVrY6zK3+lxMW5Kqqqo84/X9vCF+yDVyDbFBrpFr8cAVPwAAAEdQ+AEAADiCwg8AAMARFH4AAACOoPADAABwRJPp6vXrFqpLh095eblnvL4XZQ6FQp5xv24h24LR9f0c1EV9dj/Fas6oHXKNXENskGvkWjxwxQ8AAMARFH4AAACOoPADAABwBIUfAACAIyj8AAAAHEHhBwAA4IgmczuXWKnLQs5+7ei24/mdx7bN1kJf0xxsbG3nfnOzOVMXs0bDIdfINcQGuUaunYorfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAcQeEHAADgiCbT1VvfCx8XFBR4xnv27GkdY1tk2q8rybYtKSmp1mP8zmN7fmwdW5KUmFj7P7/tPGfqYtYuItfINcQGuUauxQNX/AAAABxB4QcAAOAICj8AAABHUPgBAAA4gsIPAADAERR+AAAAjmgyt3Opb9nZ2Z7x9PR06xhbm3irVq2sY+qymLVfS3xt+bW921rV8/PzrWPS0tI84927d6/dxOT/HPi1+KNpIdfINcQGuUauRYMrfgAAAI6g8AMAAHAEhR8AAIAjKPwAAAAcQeEHAADgiCbT1RsIBKzb6rIo8vvvv+8Z//vf/24dc+jQIc94XbqV/Dp/Dh8+7Bn3e5y258e2ALdk7zAqLy+3jmnRooVnfOvWrdYxtT0/4otcI9cQG+QauRYPXPEDAABwBIUfAACAIyj8AAAAHEHhBwAA4AgKPwAAAEdE1dVbl+6i+lbfczh+/Lhn3K8jxzbGb91AG7/up7KyMs94Y+h+sj0HFRUV1jGNWWN4bZ+qMcyHXCPXGkJjeG2fqjHMh1wj1xpCTa+rgInilffFF1+oc+fO9TYpoLHIz89Xp06d4j2NMHINZypyDYiNmnItqsIvFAqpoKBAmZmZvvcdApoKY4xKS0vVoUMH33+lxhq5hjMNuQbERrS5FlXhBwAAgKav8fzzCwAAAA2Kwg8AAMARFH4AAACOoPADAABwBIUfAACAIyj8AAAAHEHhBwAA4Ij/ByxLqzWPMY9+AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data 전처리\n",
        "\n",
        "#image를 0-1사이 값으로 만들기 위해서 255로 나누어줌\n",
        "train_images = train_images.astype(np.float32)/255.\n",
        "test_images = test_images.astype(np.float32)/255.\n",
        "\n",
        "#one-hot encoding\n",
        "train_labels = keras.utils.to_categorical(train_labels,10)\n",
        "test_labels = keras.utils.to_categorical(test_labels,10)"
      ],
      "metadata": {
        "id": "Le8WRNUtEFSo"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images,train_labels)).shuffle(buffer_size=1000000).batch(64)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((train_images,train_labels)).batch(64)"
      ],
      "metadata": {
        "id": "4W5DZIZXLH_P"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs,lbs = next(iter(train_dataset))\n",
        "\n",
        "img = imgs[0]\n",
        "lb = lbs[0]\n",
        "plt.imshow(img,cmap='gray')\n",
        "plt.show()\n",
        "print(f\"Label: {lb}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "auyhPlr5LIHf",
        "outputId": "2e8e6b7c-0ff4-451f-cb2f-27484438209c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "mufckTisQAq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#keras Sequential API\n",
        "def create_seq_model():\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "  model.add(keras.layers.Dense(128,activation='relu'))\n",
        "  model.add(keras.layers.Dropout(0.2))\n",
        "  model.add(keras.layers.Dense(10,activation='softmax'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "COjqTOr2LIKZ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#keras Functional API\n",
        "def create_func_model():\n",
        "  inputs = keras.Input(shape=(28,28))\n",
        "  flatten = keras.layers.Flatten(inputs)\n",
        "  dense = keras.laters.Dense(128,activation='relu')(flatten)\n",
        "  drop = keras.layers.Dropout(0.2)(dense)\n",
        "  outputs = keras.layers.Dense(10,activation='softmax')(drop)\n",
        "  model = keras.Model(inputs=inputs,outputs=outputs)"
      ],
      "metadata": {
        "id": "iiwtJ6r4RFlM"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model class subclassing\n",
        "class SubClassModel(keras.Model):\n",
        "  def __init__(self):\n",
        "    self.flatten = keras.layers.Flatten(input_shape=(28,28))\n",
        "    self.dense1 = keras.layers.Dense(128,activation='relu')\n",
        "    self.drop = keras.layers.Dropout(0.2)\n",
        "    self.dense2 = keras.layers.Dense(10,activation='softmax')\n",
        "  def call(self,x,training=False):\n",
        "    x=self.flatten(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.drop(x)\n",
        "    return self.dense2(x)\n"
      ],
      "metadata": {
        "id": "Dk5AuXq9SPa8"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2LABpdcXUjWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G8TnGW3vVdeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eKXa87sjVdf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BciPYEC0Vdhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "giINn1ujVdis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DaMw5oqDVdkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DdjIB019Vdnu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}